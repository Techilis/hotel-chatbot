# -*- coding: utf-8 -*-
"""Chatbot Main Code.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16er2id_ubgSrqHI6qvtmwu76TFP3ata5
"""

!pip -q install "langchain>=0.2" langchain-core langchain-community \
               langchain-huggingface sentence-transformers \
               weaviate-client gradio cohere requests

# =========================================================
# 1. Imports
# =========================================================

import gradio as gr, json, re, cohere, weaviate, requests
from datetime import datetime, timedelta
from sentence_transformers import SentenceTransformer
from typing import List, Any,Optional

from langchain_core.prompts     import PromptTemplate
from langchain_core.documents   import Document
from langchain_core.retrievers  import BaseRetriever
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain.chains           import LLMChain
from langchain.memory           import ConversationBufferMemory
from langchain_community.llms   import HuggingFaceHub
import weaviate.classes as wvc
from weaviate.collections.classes.filters import Filter
import numpy as np
from datetime import datetime


#============================
# 2. üîë  Keys / endpoints
# =========================================================
COHERE_API_KEY        = "q6h2HBR3d60g6vgzZEMB6mEuRnzQYKzN88z5UK57"
HF_API_TOKEN          = "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"
WEAVIATE_HOST         = "34.87.173.122"
WEAVIATE_GRPC_PORT    = 50051
WEAVIATE_HTTP_PORT    = 8080
RAPIDAPI_KEY = "f272c670d5mshf9cd844725a3097p186acejsn3776a6ee6894"

# =========================================================
# 3. External clients
# =========================================================
co = cohere.Client(COHERE_API_KEY)

wv_client = weaviate.connect_to_custom(
    http_host = WEAVIATE_HOST,   http_port = WEAVIATE_HTTP_PORT,   http_secure = False,
    grpc_host = WEAVIATE_HOST,   grpc_port = WEAVIATE_GRPC_PORT,   grpc_secure = False,
    skip_init_checks = True
)
print("‚úÖ Weaviate ready:", wv_client.collections.list_all())

embedder = SentenceTransformer("all-MiniLM-L6-v2")

llm      = HuggingFaceHub(
             repo_id = "mistralai/Mistral-7B-Instruct-v0.3",
             huggingfacehub_api_token = HF_API_TOKEN,
             model_kwargs = {"temperature":0.2, "max_new_tokens":512,"return_full_text": False}

           )

memory = ConversationBufferMemory(return_messages=True)
last_recommended_hotels = []
conversation_state = {
    "pending_intent": None,
    "pending_query":  None,
    "need_budget":    False,
}

# =========================================================
# 4. Intents
# =========================================================

INTENTS = {
    "RECOMMENDATION": "recommendation",
    "REVIEW_LOOKUP": "review_lookup",
    "BOOKING_CHECK": "booking_check",
    "GREETING": "greeting",
    "OTHER": "other"
}
intent_prompt = PromptTemplate(
    input_variables=["user_input"],
    template="""
You are an intent classifier for a hotel assistant chatbot.

Classify ONLY with one of these 5 labels:
RECOMMENDATION, REVIEW_LOOKUP, BOOKING_CHECK, GREETING, OTHER

You must respond with EXACTLY one of these 5 labels and nothing else.

Instructions:
- If the user asks about hotel suggestions, recommendations, or mentions hotel features/amenities, classify as RECOMMENDATION.
- If the user asks about opinions, reviews, analyse, or what others think about hotels, classify as REVIEW_LOOKUP.
- If the user asks about hotel availability, bookings, or dates (e.g., "Is Hotel XYZ available from May 1 to May 3?"), classify as BOOKING_CHECK. Keyword is 'available'
- If the user greets or thanks the assistant, classify as GREETING.
- For anything else, classify as OTHER.

Examples:
"Any 5 star hotels with a pool?" ‚Üí RECOMMENDATION
"Are there any hotels with late checkout?" ‚Üí RECOMMENDATION
"Recomment me hotels near airport with 24h checkin"‚Üí RECOMMENDATION
"What do guests say about Marina Bay Sands?" ‚Üí REVIEW_LOOKUP
"How are the reviews" ‚Üí REVIEW_LOOKUP
"Is Wanderlust Hotel available for June 1-3?" ‚Üí BOOKING_CHECK
"Is The Fullerton available from June 10 to June 12?" ‚Üí BOOKING_CHECK
"Can I book MBS for next weekend?" ‚Üí BOOKING_CHECK
"Hello, thank you!" ‚Üí GREETING
"Tell me a joke." ‚Üí OTHER

Now classify:
"{user_input}"

Classification:
"""
)

intent_chain = LLMChain(llm=llm, prompt=intent_prompt)

# =========================================================
# 5. RECCOMENDATION FILTERS
# =========================================================

# extracting filters from prompt
llm_extract = HuggingFaceHub(
  repo_id="mistralai/Mistral-7B-Instruct-v0.3",
  huggingfacehub_api_token=HF_API_TOKEN,
  model_kwargs={
    "temperature": 1, #different temp from original LLM pipeline
    "max_new_tokens": 100,
    "stop": ["\n\n"],   # stops at first blank line after JSON
    "return_full_text": False
  }
)

# 1) Define the extraction prompt
extract_prompt = PromptTemplate(
    input_variables=["q"],
    template="""
Parse the following hotel request into JSON with exactly these keys:
  ‚Ä¢ star_rating   (integer 1‚Äì5, or null)
  ‚Ä¢ max_price     (integer in SGD, or null)
  ‚Ä¢ location      (string, or null)
  ‚Ä¢ amenities     (list of strings, or empty list)

**Important:**
- If a field isn‚Äôt mentioned in the request, set it to null (or [] for amenities).
- Do **not** invent or assume any values not actually present.
- Return **only** the JSON object.

Request: {q}
"""
)

extract_chain = LLMChain(llm=llm_extract, prompt=extract_prompt)


# Helper functions

# filter for metadata
def build_filter(constraints: dict):
    filt = None
    if constraints.get("star_rating") is not None:
        cond = Filter.by_property("star_rating") \
                     .greater_or_equal(constraints["star_rating"])
        filt = cond if filt is None else filt & cond
    if constraints.get("max_price") is not None:
        cond = Filter.by_property("current_price") \
                     .less_or_equal(constraints["max_price"])
        filt = cond if filt is None else filt & cond
    if constraints.get("location"):
        cond = Filter.by_property("address") \
                     .contains_any([constraints["location"]])
        filt = cond if filt is None else filt & cond
    return filt

# Snippet‚Äêfilter helper
def get_snippets_for_hotels(query: str, hotel_names: List[str]) -> List[Document]:
    # pull k candidates from your existing retriever
    candidates = retriever.get_relevant_documents_with_topics(query, positive_only=True)
    # keep only those whose hotel_name is in our filtered list
    out = []
    for doc in candidates:
        name = doc.page_content.split("|",1)[0].strip()
        if name in hotel_names:
            out.append(doc)
    return out

# =========================================================
# 6. Helper functions
# =========================================================
NEG_PAT = re.compile(
    r"\b(no|not|none|without|lack|few|little|poor|bad|terrible|awful|dirty|smelly|disappoint)\b",
    re.I,
)                                                       #  <<< EDITED

def looks_negative(text:str)->bool:
    return bool(NEG_PAT.search(text))                   #  <<< EDITED

# def user_provided_budget(text:str)->bool:               #  <<< NEW
#     return bool(re.search(r"\$\s*\d|\d+\s*(sgd|dollars)", text, re.I))

def user_provided_budget(text: str) -> bool:
    text = text.strip()
    # 1) Pure integer ‚Üí treat as budget
    if re.fullmatch(r"\d+", text):
        return True
    # 2) Still allow things like ‚Äú$300‚Äù, ‚Äú300 SGD‚Äù or ‚Äú300 dollars‚Äù
    return bool(re.search(r"\$\s*\d+|\d+\s*(sgd|dollars)", text, re.I))

def parse_dates(date_text):
    """Convert relative dates to actual dates"""
    today = datetime.now().date()

    if not date_text or date_text == "null":
        return None

    # Handle relative dates
    date_lower = date_text.lower()
    if "tomorrow" in date_lower:
        return (today + timedelta(days=1)).strftime("%Y-%m-%d")
    elif "next week" in date_lower:
        return (today + timedelta(days=7)).strftime("%Y-%m-%d")
    elif "next month" in date_lower:
        # Approximation
        return (today + timedelta(days=30)).strftime("%Y-%m-%d")

    # Try to parse standard formats
    try:
        # Try different formats
        for fmt in ["%Y-%m-%d", "%d/%m/%Y", "%d-%m-%Y", "%m/%d/%Y"]:
            try:
                return datetime.strptime(date_text, fmt).strftime("%Y-%m-%d")
            except ValueError:
                continue
    except:
        pass

    return date_text

def search_hotel_id(hotel_name, location="Singapore"):
    """Search for hotel ID from name using Booking.com API"""
    url = "https://booking-com15.p.rapidapi.com/api/v1/hotels/searchDestination"
    headers = {
        "x-rapidapi-host": "booking-com15.p.rapidapi.com",
        "x-rapidapi-key": RAPIDAPI_KEY
    }
    params = {"query": hotel_name}
    try:
        response = requests.get(url, headers=headers, params=params)
        results = response.json().get("data", [])
        for r in results:
            if location.lower() in r.get("region", "").lower():
                return r.get("dest_id")
        return results[0]["dest_id"] if results else None
    except Exception as e:
        print(f"Error searching hotel: {str(e)}")
        return None

def fetch_room_availability(hotel_id, checkin, checkout, adults=2):
    """Fetch room availability from Booking.com API"""
    url = "https://booking-com15.p.rapidapi.com/api/v1/hotels/getRoomListWithAvailability"
    headers = {
        "x-rapidapi-host": "booking-com15.p.rapidapi.com",
        "x-rapidapi-key": RAPIDAPI_KEY
    }
    params = {
        "hotel_id": hotel_id,
        "arrival_date": checkin,
        "departure_date": checkout,
        "adults": adults,
        "room_qty": 1,
        "units": "metric",
        "languagecode": "en-us",
        "currency_code": "SGD",
    }
    try:
        res = requests.get(url, headers=headers, params=params).json()
        rooms = res.get("available", [])
        if not rooms:
            return "No available rooms for these dates."

        result = f"Available rooms at for {checkin} to {checkout}:\n\n"
        for r in rooms[:4]:  # Show up to 4 room options
            price = r['product_price_breakdown']['all_inclusive_amount']['value']
            result += f"‚Ä¢ {r['room_name']}: SGD ${price:.2f}\n"
        return result
    except Exception as e:
        print(f"Error fetching rooms: {str(e)}")
        return "‚ö†Ô∏è Error retrieving room availability."

def check_hotel_reference(query, recent_hotels):
    """Check if query refers to hotels mentioned earlier"""
    reference_terms = ["it", "that hotel", "this one", "the first one", "the last one",
                      "these hotels", "those hotels", "them"]
    if any(term in query.lower() for term in reference_terms) and recent_hotels:
        return True
    return False

def cosine_similarity(a: np.ndarray, b: np.ndarray) -> float:
    return float(np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b)))

def extract_first_valid_json(raw_response):
    try:
        # Find all JSON-like blocks
        matches = re.findall(r"\{[\s\S]*?\}", raw_response)

        for m in matches:
            try:
                parsed = json.loads(m)
                if "hotel_name" in parsed and "checkin" in parsed:
                    return parsed  # Return first valid JSON
            except json.JSONDecodeError:
                continue  # If failed to parse, move to next block

        raise ValueError("No valid JSON found.")
    except Exception as e:
        print(f"‚ùå Error extracting JSON: {e}")
        return None

# ============================
# 8. Retriever
# ============================
class WeaviateHybridCohereRetriever:
    def __init__(self, client, encoder, co_cli, k_hybrid=15, k_final=6):
        self.client = client
        self.encoder = encoder
        self.co_cli = co_cli
        self.k_hybrid = k_hybrid
        self.k_final = k_final

    def get_relevant_documents_for_hotels(
        self,
        query: str,
        hotel_names: List[str],
        *,
        positive_only: bool = False
    ) -> List[Document]:
        """
        Hybrid‚Äêsearch review chunks, but only for the given hotel_names.
        """
        vec = self.encoder.encode(query).tolist()
        rc  = self.client.collections.get("ReviewChunk")

        # Build the GraphQL‚Äêstyle where clause on hotel.hotel_name ‚àà hotel_names
        where = {
            "path":      ["hotel","hotel_name"],
            "operator":  "In",
            "valueList": hotel_names
        }

        # Run hybrid search with that filter
        res = rc.query.hybrid(
            query=        query,
            vector=       vec,
            alpha=        0.5,
            limit=        self.k_hybrid,
            #where=        where,
            return_properties=[
                "chunk_text",
                "review_traveler_type",
                "review_stay_date",
                "hotel_name"
            ],
            return_references=[wvc.query.QueryReference(
                link_on="hotel",
                return_properties=[
                    "hotel_name","star_rating","current_price","address"
                ]
            )]
        )

        # Rerank via Cohere
        chunks = [o.properties["chunk_text"] for o in res.objects]
        top_n  = min(self.k_final, len(chunks))
        reranked = self.co_cli.rerank(query=query, documents=chunks, top_n=top_n).results

        # Build Document list
        docs = []
        for r in reranked:
            obj = res.objects[r.index]
            rev = obj.properties["chunk_text"]
            if positive_only and looks_negative(rev):
                continue

            h = obj.references["hotel"].objects[0].properties
            snippet = (
                f"{h['hotel_name']} | {h.get('star_rating','?')}‚≠ê | ${h.get('current_price','N/A')}\n"
                f"üìç {h.get('address','')}\n"
                f"üí¨ \"{rev.strip()}\" "
                f"({obj.properties['review_traveler_type']}, {obj.properties['review_stay_date']})"
            )
            docs.append(Document(page_content=snippet))

        return docs

    def get_relevant_documents_with_topics(
        self,
        query: str,
        hotel_names: Optional[List[str]] = None,
        *,
        positive_only: bool = False
    ) -> List[Document]:
        """
        Hybrid‚Äêsearch review chunks, enriched with topic sentiment.
        If `hotel_names` is provided, only snippets for those hotels are kept.
        """
        vec     = self.encoder.encode(query).tolist()
        rc      = self.client.collections.get("ReviewChunk")
        topic_c = self.client.collections.get("HotelReviewTopic")

        # 1) Hybrid search (no 'where', unsupported)
        res = rc.query.hybrid(
            query=query, vector=vec, alpha=0.5, limit=self.k_hybrid,
            return_properties=[
                "chunk_text","review_traveler_type","review_stay_date","hotel_name"
            ],
            return_references=[wvc.query.QueryReference(
                link_on="hotel",
                return_properties=["hotel_name","star_rating","current_price","address"]
            )]
        )

        # 2) Enrich + filter by hotel_names
        enriched_texts = []
        metas          = []
        for obj in res.objects:
            name = obj.properties.get("hotel_name","").strip()
            if hotel_names and name not in hotel_names:
                continue

            chunk = obj.properties["chunk_text"]
            topic_score = None
            # fetch topic sentiment if any
            try:
                topic_res = topic_c.query.fetch_objects(
                    filters=Filter.by_property("hotel_name").equal(name),
                    limit=5,
                    return_properties=[
                        "main_topic_category","sub_topic_category","positive_sentiment_ratio"
                    ]
                )
                for t in topic_res.objects:
                    m = t.properties.get("main_topic_category","").lower()
                    s = t.properties.get("sub_topic_category","").lower()
                    if m in query.lower() or s in query.lower():
                        topic_score = t.properties["positive_sentiment_ratio"]
                        break
            except:
                pass

            # weave score into the chunk for reranking
            text = chunk + (f"\n\n[Topic Sentiment Score: {topic_score}]" if topic_score is not None else "")
            enriched_texts.append(text)
            metas.append((obj, topic_score))

        # 3) Cohere‚Äêrerank
        top_n  = min(self.k_final, len(enriched_texts))
        rerank = self.co_cli.rerank(query=query, documents=enriched_texts, top_n=top_n).results

        # 4) Build Document list
        docs = []
        for r in rerank:
            obj, topic_score = metas[r.index]
            rev = obj.properties["chunk_text"]
            if positive_only and looks_negative(rev):
                continue
            h = obj.references["hotel"].objects[0].properties
            snippet = (
                f"{h['hotel_name']} | {h.get('star_rating','?')}‚≠ê | ${h.get('current_price','N/A')}\n"
                f"üìç {h.get('address','')}\n"
                f"üí¨ \"{rev.strip()}\" "
                f"({obj.properties['review_traveler_type']}, {obj.properties['review_stay_date']})"
            )
            if topic_score is not None:
                snippet += f"\nüü¢ Topic Sentiment Score: {topic_score}"
            docs.append(Document(page_content=snippet))

        return docs


retriever = WeaviateHybridCohereRetriever(client=wv_client, encoder=embedder, co_cli=co)

# =========================================================
#  9. Prompt templates
# =========================================================
current_year = datetime.now().year

recommendation_prompt = PromptTemplate(
    input_variables=["context", "question", "history"],
    template="""

You are a helpful hotel assistant. ONLY use the context provided to recommend hotels.

<context>
{context}
</context>

<conversation_history>
{history}
</conversation_history>

<user_question>
{question}
</user_question>

### RECOMMENDATION:
Provide exactly **three** hotel recommendations, each on its own numbered line:
1. Hotel Name | ‚≠êStarRating | SGD Price
   ‚Ä¢ Key amenities or features
   ‚Ä¢ A highlight from a positive review

Do **not** output anything else.
"""
)

review_prompt = PromptTemplate(
    input_variables=["context", "question", "history"],
    template="""
You are a hotel review assistant. ONLY use the context provided.

<context>
{context}
</context>

<conversation_history>
{history}
</conversation_history>

<user_question>
{question}
</user_question>

### REVIEW SUMMARY:
Provide a balanced summary of reviews for the hotels mentioned in the context.
For each hotel, mention:
1. Overall guest sentiment
2. Key strengths praised in reviews
3. Common complaints or issues
4. Specific comments from different traveler types when available
"""
)

booking_prompt = PromptTemplate(
    input_variables=["user_input"],
    template=f"""
Today's year is {current_year}.

Extract hotel name, check-in date, and check-out date as JSON:
{{{{"hotel_name": "...", "checkin": "YYYY-MM-DD", "checkout": "YYYY-MM-DD"}}}}
- Return only **one single line of JSON** ‚Äî no explanations, no extra examples.
- If dates are relative (e.g., "tomorrow", "next week"), convert them.
- If no year is provided, assume the current year. (e.g. "June 1" will be "2025-06-01")
- If no hotel is mentioned, set "hotel_name" to null.
- If dates are missing, set them to null.

User: {{user_input}}

JSON:
"""
)
booking_info_chain = LLMChain(llm=llm, prompt=booking_prompt)

# =========================================================
# 10. Chain that "stuffs" docs into the prompt
# =========================================================
rec_chain = create_stuff_documents_chain(llm, recommendation_prompt)
rev_chain = create_stuff_documents_chain(llm, review_prompt)


default_prompt = PromptTemplate(
    input_variables=["question", "history"],
    template="""
You are a helpful, knowledgeable assistant that can answer any general question the user might have.
Use the conversation history only for context‚Äîbut feel free to go beyond it if you know the answer.
Answer the user‚Äôs question directly, concisely, and factually.
Conversation history:
{history}

User asks:
{question}

Assistant:"""
)

# 2) Wrap it in a chain
default_chain = LLMChain(llm=llm, prompt=default_prompt)

# =========================================================
# 11. MAIN CHAT FUNCTION
# =========================================================
def chat(user_input: str, chat_hist: list):
    global last_recommended_hotels, conversation_state

    display_input = user_input
    skip_budget_question = False

    # 1) Handle pending‚Äêbudget state
    if conversation_state.get("need_budget"):
        state = conversation_state
        # how many times we‚Äôve already re-asked
        count = state.get("budget_ask_count", 0)

        # a) they finally gave a number
        if user_provided_budget(user_input):
            budget_val = re.search(r"\d+", user_input).group(0)
            user_input = f"{state['pending_query']} under ${budget_val}"
            # clear out the budget state entirely
            conversation_state = {
                "pending_intent":   None,
                "pending_query":    None,
                "need_budget":      False,
                "budget_ask_count": 0
            }

        # b) they explicitly say ‚Äúno‚Äù ‚Üí skip budget
        elif user_input.strip().lower() in ("no", "no thanks", "no thank you"):
            user_input = state["pending_query"]
            skip_budget_question = True
            conversation_state = {
                "pending_intent":   None,
                "pending_query":    None,
                "need_budget":      False,
                "budget_ask_count": 0
            }

        # c) they gave neither a number nor ‚Äúno‚Äù
        else:
            if count < 1:
                # first re-ask
                state["budget_ask_count"] = count + 1
                answer = "Could you tell me roughly how much you‚Äôd like to spend per night?"
                chat_hist.append((display_input, answer))
                return chat_hist, chat_hist
            else:
                # second time still no budget ‚Üí give up and proceed
                user_input = state["pending_query"]
                skip_budget_question = True
                conversation_state = {
                    "pending_intent":   None,
                    "pending_query":    None,
                    "need_budget":      False,
                    "budget_ask_count": 0
                }

    # 2) Build recent history
    history_txt = "\n".join(f"User: {u}\nAssistant: {a}"
                            for u, a in chat_hist[-5:])

    # 3) Classify intent
    raw_intent = intent_chain.invoke({"user_input": user_input})["text"].strip().upper()
    intent     = INTENTS.get(raw_intent, "other")
    # DEBUG: show last_recommended_hotels
    print("üõ†Ô∏è DEBUG intent:", intent)

    # 4) Ask for budget if this is a recommendation and we haven‚Äôt yet‚Äîand they haven‚Äôt opted out
    if (
        intent == "recommendation"
        and not user_provided_budget(user_input)
        and not skip_budget_question
    ):
        answer = "Sure‚Äîdo you have a nightly budget in mind?"
        chat_hist.append((display_input, answer))
        conversation_state = {
            "pending_intent":   "recommendation",
            "pending_query":    user_input,
            "need_budget":      True,
            "budget_ask_count": 0
        }
        return chat_hist, chat_hist

    # 5) Handle each intent
    if intent == "recommendation":
        # Step¬†1: parse constraints
        raw = extract_chain.invoke({"q": user_input})
        text = raw["text"] if isinstance(raw, dict) else raw
        m = re.search(r"\{[\s\S]*\}", text)
        constraints = json.loads(m.group(0))

        # Step¬†2: metadata filter
        filt = build_filter(constraints)
        hotel_coll = wv_client.collections.get("Hotel")
        resp = hotel_coll.query.fetch_objects(
            return_properties=["hotel_name","hotel_id","star_rating","current_price","address"],
            limit=20,
            filters=filt
        )
        hotels = resp.objects
        hotel_names = [h.properties["hotel_name"] for h in hotels]

        # Step¬†3: semantic snippets for those hotels
        snippets = retriever.get_relevant_documents_for_hotels(
            query=user_input,
            hotel_names=hotel_names,
            positive_only=True
        )

        # Step¬†3a: filter for requested amenities
        requested_amenities = constraints.get("amenities", [])
        if requested_amenities:
            filtered = [
                doc for doc in snippets
                if any(a.lower() in doc.page_content.lower() for a in requested_amenities)
            ]
            use_snippets = filtered or snippets
        else:
            use_snippets = snippets

        # Step¬†3b: dedupe so each hotel appears once
        unique_snippets = []
        seen = set()
        for doc in use_snippets:
            name = doc.page_content.split("|", 1)[0].strip()
            if name not in seen:
                seen.add(name)
                unique_snippets.append(doc)
            if len(unique_snippets) == 3:
                break

        # DEBUG: inspect which three we‚Äôll recommend
        print("üõ†Ô∏è DEBUG unique top3 snippets:")
        for i, doc in enumerate(unique_snippets, 1):
            hotel_name = doc.page_content.split("|",1)[0].strip()
            print(f"  {i}. {hotel_name}")

        # Step¬†4: final recommendation
        answer = rec_chain.invoke({
            "context":  unique_snippets,
            "question": user_input,
            "history":  history_txt
        }).split("###")[-1].strip()

        # Step¬†5: store those three hotel names
        last_recommended_hotels[:] = [
            doc.page_content.split("|", 1)[0].strip()
            for doc in unique_snippets
        ]

        # DEBUG: show last_recommended_hotels
        print("üõ†Ô∏è DEBUG last_recommended_hotels:", last_recommended_hotels)


    elif intent == "review_lookup":
        # build history
        history_txt = "\n".join(f"User: {u}\nAssistant: {a}" for u,a in chat_hist[-5:])

        # decide hotels_to_lookup
        m = re.search(r"reviews? for (.+)", user_input, flags=re.IGNORECASE)
        if m:
            hotels_to_lookup = [m.group(1).strip()]
            review_query     = f"Reviews for {hotels_to_lookup[0]}"
        elif last_recommended_hotels:
            hotels_to_lookup = last_recommended_hotels
            review_query     = f"Reviews for {', '.join(hotels_to_lookup)}"
        else:
            hotels_to_lookup = None
            review_query     = user_input

        # DEBUG
        print("üõ†Ô∏è DEBUG hotels to lookup:", hotels_to_lookup)

        # fetch only for those names
        docs = retriever.get_relevant_documents_with_topics(
            review_query,
            hotel_names=hotels_to_lookup,
            positive_only=False
        )

        answer = rev_chain.invoke({
            "context":  docs,
            "question": review_query,
            "history":  history_txt
        }).split("###")[-1].strip()

        # # reorder
        # def snippet_name(doc: Document) -> str:
        #     # grab hotel name from the snippet string
        #     return doc.page_content.split("|", 1)[0].strip()

        # # build a lookup from name ‚Üí rank
        # order = {name: i for i, name in enumerate(hotels_to_lookup)}
        # # keep only docs whose name is in hotels_to_lookup, then sort
        # docs = sorted(
        #     [d for d in docs if snippet_name(d) in order],
        #     key=lambda d: order[snippet_name(d)]
        # )
        # # if for some reason a hotel had no snippet, you can append them at end:
        # missing = [n for n in hotels_to_lookup if n not in {snippet_name(d) for d in docs}]
        # for n in missing:
        #     docs.append(Document(page_content=f"{n} | No reviews found."))

        print("üõ†Ô∏è DEBUG retrieved review snippets:", docs)
        # 3) Generate the summary
        answer = rev_chain.invoke({
            "context":  docs,
            "question": review_query,
            "history":  history_txt
        }).split("###")[-1].strip()


    elif intent == "booking_check":
        # 1) Ask LLM to extract name & dates
        booking_resp = booking_info_chain.invoke({
            "user_input": user_input
        })
        booking_json = booking_resp["text"].strip()
        print("üõ†Ô∏è DEBUG booking_json:", booking_json)
        booking_json = extract_first_valid_json(booking_json)

        # 2) Try to parse the JSON

        try:
            info = (
                booking_json if isinstance(booking_json, dict)
                else json.loads(booking_json)
            )
        except Exception as e:
            print("üõ†Ô∏è ERROR parsing booking_json:", e)
            answer = "Sorry, I couldn't parse that. Could you please specify the hotel name and dates?"

        else:
            hotel_raw    = info.get("hotel_name")
            checkin_raw  = info.get("checkin")
            checkout_raw = info.get("checkout")

            # 3a) Missing hotel name?
            if not hotel_raw:
                answer = "Which hotel would you like to check availability for?"
            # 3b) Missing one or both dates?
            elif not (checkin_raw and checkout_raw):
                answer = "Could you tell me your check-in and check-out dates (e.g. June 1 to June 3)?"
            else:
                # 4) Normalize dates (using your parse_dates util)
                checkin  = parse_dates(checkin_raw)
                checkout = parse_dates(checkout_raw)

                # 5) Look up hotel_id and fetch availability
                hotel_id = search_hotel_id(hotel_raw)
                if not hotel_id:
                    answer = f"Sorry, I couldn‚Äôt find a hotel named ‚Äú{hotel_raw}.‚Äù Could you check the name?"
                else:
                    answer = fetch_room_availability(hotel_id, checkin, checkout)

        # 6) Append and return
        chat_hist.append((display_input, answer))
        return chat_hist, chat_hist

    elif intent == "greeting":
        answer = "Hello! I'm your hotel assistant. How can I help you today?"

    else:
        # ANY OTHER intent ‚Üí route to default_chain
        answer = default_chain.invoke({
            "question": user_input,
            "history": history_txt
        })["text"].strip()


    # 6) Save & return
    memory.save_context({"input": user_input}, {"output": answer})
    chat_hist.append((display_input, answer))
    return chat_hist, chat_hist

# =========================================================
# 11. Launch Gradio UI
# =========================================================
with gr.Blocks(css="footer{display:none !important}") as demo:
    gr.Markdown("# üè® ChatHotel ‚Äî Assistant")
    chatbot = gr.Chatbot(show_copy_button=True,height=900)
    hist = gr.State([])
    with gr.Row():
        txt = gr.Textbox(placeholder="Ask about hotels‚Ä¶", scale=4, autofocus=True)
        clr = gr.Button("üóëÔ∏è Clear", scale=1)

    txt.submit(chat, [txt, hist], [chatbot, hist]).then(lambda: "", None, [txt])
    def clear_memory():
        memory.clear()
        return []

    clr.click(lambda: ([], []), None, [chatbot, hist], queue=False).then(
        lambda: [], None, [hist], queue=False).then(
        clear_memory, None, [], queue=False)

if __name__ == "__main__":
    demo.launch(share=True, inline=True,debug = True)



