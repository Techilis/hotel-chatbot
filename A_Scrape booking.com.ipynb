{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ALLOWED: Scraping is permitted for https://www.booking.com/searchresults.en-gb.html\n",
      "✅ ALLOWED: Scraping is permitted for https://www.booking.com/searchresults.en-gb.html?ss=Singapore&checkin=2025-05-01&checkout=2025-05-02&group_adults=2&no_rooms=1&group_children=0\n",
      "✅ ALLOWED: Scraping is permitted for https://www.booking.com/hotel/sg/marina-bay-sands.en-gb.html?aid=304142&label=gen173nr-1FCAQoggJCEHNlYXJjaF9zaW5nYXBvcmVICVgEaMkBiAEBmAEJuAEXyAEM2AEB6AEB-AEDiAIBqAIDuAK_n9a-BsACAdICJGQwZWQwM2I0LTczYTAtNDc1Mi04MzgzLWE3ODY2NjRiM2Y0N9gCBeACAQ&ucfs=1&arphpl=1&checkin=2025-05-01&checkout=2025-05-02&group_adults=2&req_adults=2&no_rooms=1&group_children=0&req_children=0&hpos=3&hapos=3&sr_order=popularity&srpvid=27c0665fd57806b5&srepoch=1742049218&all_sr_blocks=24588246_266353018_2_2_0_53975&highlighted_blocks=24588246_266353018_2_2_0_53975&matching_block_id=24588246_266353018_2_2_0_53975&sr_pri_blocks=24588246_266353018_2_2_0_53975_119900&from_sustainable_property_sr=1&from=searchresults\n",
      "❌ BLOCKED: Scraping is NOT permitted for https://www.booking.com/photo.html\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from urllib.robotparser import RobotFileParser\n",
    "\n",
    "def is_scraping_allowed(url):\n",
    "    \"\"\"Check if scraping is allowed for a specific Booking.com page.\"\"\"\n",
    "    robots_url = \"https://www.booking.com/robots.txt\"\n",
    "\n",
    "    try:\n",
    "        rp = RobotFileParser()\n",
    "        rp.set_url(robots_url)\n",
    "        rp.read()\n",
    "\n",
    "        if rp.can_fetch(\"*\", url):\n",
    "            print(f\"✅ ALLOWED: Scraping is permitted for {url}\")\n",
    "        else:\n",
    "            print(f\"❌ BLOCKED: Scraping is NOT permitted for {url}\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ ERROR: Could not check robots.txt for {url} - {e}\")\n",
    "\n",
    "# ✅ Test search results page\n",
    "is_scraping_allowed(\"https://www.booking.com/searchresults.en-gb.html\")\n",
    "is_scraping_allowed(\"https://www.booking.com/searchresults.en-gb.html?ss=Singapore&checkin=2025-05-01&checkout=2025-05-02&group_adults=2&no_rooms=1&group_children=0\")\n",
    "is_scraping_allowed(\"https://www.booking.com/hotel/sg/marina-bay-sands.en-gb.html?aid=304142&label=gen173nr-1FCAQoggJCEHNlYXJjaF9zaW5nYXBvcmVICVgEaMkBiAEBmAEJuAEXyAEM2AEB6AEB-AEDiAIBqAIDuAK_n9a-BsACAdICJGQwZWQwM2I0LTczYTAtNDc1Mi04MzgzLWE3ODY2NjRiM2Y0N9gCBeACAQ&ucfs=1&arphpl=1&checkin=2025-05-01&checkout=2025-05-02&group_adults=2&req_adults=2&no_rooms=1&group_children=0&req_children=0&hpos=3&hapos=3&sr_order=popularity&srpvid=27c0665fd57806b5&srepoch=1742049218&all_sr_blocks=24588246_266353018_2_2_0_53975&highlighted_blocks=24588246_266353018_2_2_0_53975&matching_block_id=24588246_266353018_2_2_0_53975&sr_pri_blocks=24588246_266353018_2_2_0_53975_119900&from_sustainable_property_sr=1&from=searchresults\") # expected yes, defined on robots.txt\n",
    "\n",
    "# ❌ Test photo page - expected no, defined on robots.txt\n",
    "is_scraping_allowed(\"https://www.booking.com/photo.html\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marina-bay-sands\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.booking.com/hotel/sg/marina-bay-sands.en-gb.html?aid=304142&label=gen173nr-1FCAQoggJCEHNlYXJjaF9zaW5nYXBvcmVICVgEaMkBiAEBmAEJuAEXyAEM2AEB6AEB-AEDiAIBqAIDuAK_n9a-BsACAdICJGQwZWQwM2I0LTczYTAtNDc1Mi04MzgzLWE3ODY2NjRiM2Y0N9gCBeACAQ&ucfs=1&arphpl=1&checkin=2025-05-01&checkout=2025-05-02&group_adults=2&req_adults=2&no_rooms=1&group_children=0&req_children=0&hpos=3&hapos=3&sr_order=popularity&srpvid=27c0665fd57806b5&srepoch=1742049218&all_sr_blocks=24588246_266353018_2_2_0_53975&highlighted_blocks=24588246_266353018_2_2_0_53975&matching_block_id=24588246_266353018_2_2_0_53975&sr_pri_blocks=24588246_266353018_2_2_0_53975_119900&from_sustainable_property_sr=1&from=searchresults\"\n",
    "parts = url.split(\"/\")\n",
    "slug = parts[5]\n",
    "\n",
    "clean_slug = slug.split(\".\")[0]  \n",
    "print(clean_slug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Extracting Property Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "No more results to load or button not found\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "No more results to load or button not found\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "No more results to load or button not found\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "No more results to load or button not found\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "No more results to load or button not found\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "No more results to load or button not found\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "No more results to load or button not found\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "No more results to load or button not found\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "No more results to load or button not found\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "No more results to load or button not found\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "No more results to load or button not found\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "No more results to load or button not found\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "No more results to load or button not found\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "No more results to load or button not found\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "No more results to load or button not found\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "No more results to load or button not found\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "No more results to load or button not found\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "Button found, clicking it...\n",
      "No more results to load or button not found\n",
      "Saved 444 unique hotel listings to property_data.csv\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import datetime\n",
    "import csv\n",
    "import re\n",
    "\n",
    "# --------------------------\n",
    "# 1. Define function to scrape property listings\n",
    "# --------------------------\n",
    "\n",
    "def scrape_property_listings(checkin_date, checkout_date):\n",
    "    \n",
    "    # 2. Construct Booking.com Search URL\n",
    "    BASE_URL = \"https://www.booking.com/searchresults.en-gb.html\"\n",
    "    SEARCH_URL = f\"{BASE_URL}?ss=Singapore&checkin={checkin_date}&checkout={checkout_date}&group_adults=2&no_rooms=1&group_children=0\"\n",
    "\n",
    "    # 3. Initialize WebDriver\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(SEARCH_URL)\n",
    "    time.sleep(5)\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "\n",
    "    # 4. Extract property details from search results\n",
    "    property_data = {}\n",
    "\n",
    "    # Loop to scroll and click \"Load more results\" button\n",
    "    while True:\n",
    "        try:\n",
    "            # Scroll to the bottom of the page to trigger lazy loading\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(5)  # Wait for new content to load\n",
    "\n",
    "            # Check if \"Load more results\" button exists\n",
    "            load_more_button = driver.find_element(By.XPATH, '//button[span[text()=\"Load more results\"]]')\n",
    "            print(\"Button found, clicking it...\")\n",
    "            driver.execute_script(\"arguments[0].click();\", load_more_button)\n",
    "            time.sleep(5)\n",
    "            \n",
    "        except Exception as e:\n",
    "            # Break if no more \"Load more results\" button\n",
    "            print(\"No more results to load or button not found\")\n",
    "            break\n",
    "\n",
    "    properties = driver.find_elements(By.XPATH, '//div[@data-testid=\"property-card-container\"]')\n",
    "\n",
    "    for prop in properties:\n",
    "        try:\n",
    "            # Extract hotel name and link\n",
    "            hotel_name = prop.find_element(By.XPATH, './/div[@data-testid=\"title\"]').text.strip()\n",
    "            hotel_url = prop.find_element(By.XPATH, './/a').get_attribute(\"href\")\n",
    "\n",
    "            # Extract prices\n",
    "            try:\n",
    "                original_price_elem = prop.find_element(By.XPATH, './/span[@aria-hidden=\"true\" and contains(@class, \"abf093bdfe\")]')\n",
    "                original_price_text = original_price_elem.text.strip().replace(\"S$\", \"\").replace(\",\", \"\").strip()\n",
    "                original_property_price = int(original_price_text)\n",
    "            except:\n",
    "                original_property_price = \"N/A\"\n",
    "\n",
    "            try:\n",
    "                current_price_elem = prop.find_element(By.XPATH, './/span[@data-testid=\"price-and-discounted-price\"]')\n",
    "                current_price_text = current_price_elem.text.strip().replace(\"S$\", \"\").replace(\",\", \"\").strip()\n",
    "                current_property_price = int(current_price_text)\n",
    "            except:\n",
    "                current_property_price = \"N/A\"\n",
    "\n",
    "            # Extract review score\n",
    "            try:\n",
    "                review_score_elem = prop.find_element(By.XPATH, './/div[@data-testid=\"review-score\"]/div')\n",
    "                review_score = review_score_elem.text.strip().split(\"\\n\")[-1]\n",
    "            except:\n",
    "                review_score = \"N/A\"\n",
    "\n",
    "            # Extract review label\n",
    "            try:\n",
    "                review_label_elem = prop.find_element(By.XPATH, './/div[contains(@class, \"a3b8729ab1 e6208ee469 cb2cbb3ccb\")]')\n",
    "                review_label = review_label_elem.text.strip()\n",
    "            except:\n",
    "                review_label = \"N/A\"\n",
    "\n",
    "            # Extract number of reviews\n",
    "            try:\n",
    "                num_review_elem = prop.find_element(By.XPATH, './/div[@data-testid=\"review-score\"]//div[contains(@class, \"abf093bdfe f45d8e4c32 d935416c47\")]')\n",
    "                num_reviews = re.sub(r\"[^\\d]\", \"\", num_review_elem.text)  # Keep only digits\n",
    "            except:\n",
    "                num_reviews = \"N/A\"\n",
    "\n",
    "            # Extract star rating\n",
    "            try:\n",
    "                star_rating_elem = prop.find_element(By.XPATH, './/div[contains(@class, \"b3f3c831be\")]')\n",
    "                star_rating = star_rating_elem.get_attribute(\"aria-label\").split(\" out of \")[0]\n",
    "            except:\n",
    "                star_rating = \"N/A\"\n",
    "\n",
    "            # Extract preferred partner status\n",
    "            try:\n",
    "                prop.find_element(By.XPATH, './/span[@data-testid=\"preferred-badge\"]')\n",
    "                preferred_partner = \"Yes\"\n",
    "            except:\n",
    "                preferred_partner = \"No\"\n",
    "\n",
    "            # Extract sustainability certification\n",
    "            try:\n",
    "                prop.find_element(By.XPATH, './/div[contains(@class, \"abf093bdfe e6208ee469 f68ecd98ea\")]')\n",
    "                sustainability_certified = \"Yes\"\n",
    "            except:\n",
    "                sustainability_certified = \"No\"\n",
    "            \n",
    "\n",
    "            # Store partial property data \n",
    "            property_data[hotel_url] = {\n",
    "                \"hotel_name\": hotel_name,\n",
    "                \"hotel_url\": hotel_url,\n",
    "                \"original_price\": original_property_price,\n",
    "                \"current_price\": current_property_price,\n",
    "                \"num_reviews\": num_reviews,\n",
    "                \"review_score\": review_score,\n",
    "                \"review_label\": review_label,\n",
    "                \"star_rating\": star_rating,\n",
    "                \"preferred_partner\": preferred_partner,\n",
    "                \"sustainability_certified\": sustainability_certified,\n",
    "                \"last_updated\": datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping property due to error: {e}\")\n",
    "\n",
    "    # 6. Close the driver\n",
    "    driver.quit()\n",
    "\n",
    "    return property_data\n",
    "\n",
    "# --------------------------\n",
    "# 2. Scrape multiple dates (1st and 14th of each month)\n",
    "# --------------------------\n",
    "import pandas as pd\n",
    "\n",
    "# Generate check-in dates for the 1st and 14th of each month\n",
    "year = 2025\n",
    "first_days = pd.date_range(start=f\"{year}-04-01\", end=f\"{year}-12-01\", freq=\"MS\")  # 1st of every month\n",
    "fourteenth_days = [pd.Timestamp(f\"{year}-{month:02d}-14\") for month in range(4, 13)]  # 14th of every month\n",
    "\n",
    "# Combine the two lists\n",
    "checkin_dates = sorted(list(first_days) + fourteenth_days)\n",
    "\n",
    "# Generate (check-in, check-out) date pairs (checkout = check-in + 1 day)\n",
    "date_pairs = [(d.strftime(\"%Y-%m-%d\"), (d + pd.Timedelta(days=1)).strftime(\"%Y-%m-%d\")) for d in checkin_dates]\n",
    "\n",
    "# Store results in a dictionary using `slug` as the unique key\n",
    "all_listings = {}\n",
    "\n",
    "for checkin, checkout in date_pairs:\n",
    "    listings = scrape_property_listings(checkin, checkout)\n",
    "\n",
    "    for url, details in listings.items():\n",
    "        try:\n",
    "            parts = url.split(\"/\")\n",
    "            slug = parts[5].split(\".\")[0]  # Extract slug (e.g., \"marina-bay-sands\")\n",
    "\n",
    "            # Use slug as the unique key\n",
    "            if slug not in all_listings:\n",
    "                all_listings[slug] = details  # Store the first occurrence of the hotel\n",
    "            else:\n",
    "                pass  # Skip if the hotel has already been added\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# Save to CSV\n",
    "# --------------------------\n",
    "df = pd.DataFrame.from_dict(all_listings, orient=\"index\")\n",
    "\n",
    "csv_filename = \"property_data.csv\"\n",
    "df.to_csv(csv_filename, index=False)  \n",
    "\n",
    "print(f\"Saved {len(df)} unique hotel listings to {csv_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Extracting Details from Each Property Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# Define functions for scraping property details\n",
    "# --------------------------\n",
    "def scrape_payment_methods(driver):\n",
    "    \"\"\"\n",
    "    Extracts accepted payment methods (credit cards) and cash acceptance status.\n",
    "    \"\"\"\n",
    "    payment_methods = {\n",
    "        \"accepted_cards\": [],\n",
    "        \"cash_accepted\": \"N/A\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # Locate all payment method images inside the section (credit cards)\n",
    "        card_images = driver.find_elements(By.XPATH, \"//div[contains(@class, 'c5e805a2e8')]//picture/img\")\n",
    "\n",
    "        for img in card_images:\n",
    "            card_name = img.get_attribute(\"alt\").strip()  # Extracts Visa, Mastercard, etc.\n",
    "            if card_name:\n",
    "                payment_methods[\"accepted_cards\"].append(card_name)\n",
    "\n",
    "        # Check for \"Cash is not accepted\" explicitly\n",
    "        try:\n",
    "            cash_element = driver.find_element(By.XPATH, \"//span[contains(text(), 'Cash is not accepted')]\")\n",
    "            if cash_element:\n",
    "                payment_methods[\"cash_accepted\"] = \"No\"\n",
    "        except:\n",
    "            # Check if \"Cash\" is present alone (meaning it's accepted)\n",
    "            try:\n",
    "                cash_element = driver.find_element(By.XPATH, \"//span[contains(text(), 'Cash')]\")\n",
    "                if cash_element:\n",
    "                    payment_methods[\"cash_accepted\"] = \"Yes\"\n",
    "            except:\n",
    "                payment_methods[\"cash_accepted\"] = \"No\"  # Default assumption: Cash is not accepted\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting payment methods: {e}\")\n",
    "\n",
    "    return payment_methods\n",
    "\n",
    "\n",
    "def scrape_cot_extra_bed_policies(driver):\n",
    "    \"\"\"\n",
    "    Extracts cot and extra bed policies and returns a structured dictionary.\n",
    "    \"\"\"\n",
    "    cot_extra_bed_policies = {}\n",
    "\n",
    "    try:\n",
    "        # Locate the section header for Cot and Extra Bed Policies\n",
    "        policy_section = driver.find_element(By.XPATH, \"//h2[contains(text(), 'Cot and extra bed policies')]\")\n",
    "        policy_blocks = driver.find_elements(By.XPATH, \"//div[contains(@class, 'e88206330c')]\")\n",
    "\n",
    "        if policy_blocks:\n",
    "            for block in policy_blocks:\n",
    "                try:\n",
    "                    # Extract age group (e.g., \"0 - 2 years\", \"3+ years\")\n",
    "                    age_group = block.find_element(By.XPATH, \".//div[contains(@class, 'df14f5d170')]\").text.strip()\n",
    "                    \n",
    "                    # Find all policy entries (extra bed, cot, etc.)\n",
    "                    policies = block.find_elements(By.XPATH, \".//div[contains(@class, 'cbadf7c7a5')]\")\n",
    "                    \n",
    "                    policy_details = {}\n",
    "                    \n",
    "                    for policy_entry in policies:\n",
    "                        try:\n",
    "                            # Extract policy description (e.g., \"Extra bed upon request\", \"Cot upon request\")\n",
    "                            policy = policy_entry.find_element(By.XPATH, \".//span[contains(@class, 'f149a96297')]\").text.strip()\n",
    "                            \n",
    "                            # Extract cost (if available)\n",
    "                            try:\n",
    "                                cost = policy_entry.find_element(By.XPATH, \".//div[contains(@class, 'a53cbfa6de')]\").text.strip()\n",
    "                            except:\n",
    "                                cost = \"N/A\"  \n",
    "                            \n",
    "                            # Check for 'Free' (which is in a different div)\n",
    "                            try:\n",
    "                                free_text = policy_entry.find_element(By.XPATH, \".//div[contains(@class, 'ccb65902b2')]\").text.strip()\n",
    "                                if free_text.lower() == \"free\":\n",
    "                                    cost = \"Free\"\n",
    "                            except:\n",
    "                                pass  # If not found, ignore\n",
    "\n",
    "                            policy_details[policy] = cost\n",
    "\n",
    "                        except Exception as e:\n",
    "                            print(f\"Skipping policy entry due to error: {e}\")\n",
    "\n",
    "                    # Store extracted data in dictionary\n",
    "                    cot_extra_bed_policies[age_group] = policy_details\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Skipping policy block due to error: {e}\")\n",
    "\n",
    "        else:\n",
    "            # If no structured policies exist, check for plain text message\n",
    "            try:\n",
    "                no_cots_message = driver.find_element(By.XPATH, \"//p[contains(text(), 'Cots and extra beds')]\").text.strip()\n",
    "                cot_extra_bed_policies[\"availability\"] = no_cots_message\n",
    "            except:\n",
    "                cot_extra_bed_policies[\"availability\"] = \"N/A\"\n",
    "\n",
    "    except Exception as e:\n",
    "        cot_extra_bed_policies[\"availability\"] = \"N/A\"\n",
    "\n",
    "    return cot_extra_bed_policies\n",
    "\n",
    "\n",
    "def scrape_review_scores(driver):\n",
    "    \"\"\"\n",
    "    Extracts review categories and their corresponding scores in a database-friendly format.\n",
    "    \"\"\"\n",
    "    review_scores = []\n",
    "\n",
    "    try:\n",
    "        # Locate all review score items\n",
    "        review_items = driver.find_elements(By.XPATH, \"//ul[@id='review_list_score_breakdown']//li[contains(@class, 'clearfix one_col')]\")\n",
    "\n",
    "        for item in review_items:\n",
    "            try:\n",
    "                # Extract category name\n",
    "                category_element = item.find_element(By.XPATH, \".//p[contains(@class, 'review_score_name')]\")\n",
    "                category = category_element.get_attribute(\"innerText\").strip() if category_element else None\n",
    "\n",
    "                if not category:\n",
    "                    print(\"Warning: Missing category name, skipping item.\")\n",
    "                    continue  # Skip this entry if the category is still empty\n",
    "\n",
    "                # Extract corresponding score\n",
    "                score_element = item.find_element(By.XPATH, \".//p[contains(@class, 'review_score_value')]\")\n",
    "                score_text = score_element.get_attribute(\"innerText\").strip() if score_element else \"\"\n",
    "\n",
    "                # Handle missing or empty scores\n",
    "                if not score_text:\n",
    "                    print(f\"Warning: '{category}' score is empty. Assigning None.\")\n",
    "                    score = None  # Assign None instead of skipping\n",
    "                else:\n",
    "                    try:\n",
    "                        score = float(score_text)\n",
    "                    except ValueError:\n",
    "                        print(f\"Warning: '{category}' score '{score_text}' is invalid. Assigning None.\")\n",
    "                        score = None  # Assign None if conversion fails\n",
    "\n",
    "                # Append structured data\n",
    "                review_scores.append({\"category\": category, \"score\": score})\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Skipping review item due to error: {e}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting review scores: {e}\")\n",
    "\n",
    "    return review_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_property_details(driver):\n",
    "    \"\"\"\n",
    "    Given a Selenium driver and a Booking.com hotel URL:\n",
    "    - Loads the page\n",
    "    - Extracts the property address, description, and review details\n",
    "    Returns a dictionary with structured data.\n",
    "    \"\"\"\n",
    "    \n",
    "    wait = WebDriverWait(driver, 10)\n",
    "\n",
    "    # Initialize dictionary upfront with default values\n",
    "    property_details = {\n",
    "        \"hotel_id\": \"N/A\",\n",
    "        \"best_review_score_label\": \"N/A\",\n",
    "        \"best_review_score_rating\": \"N/A\",\n",
    "        \"review_scores\": [],\n",
    "        \"address\": \"N/A\",\n",
    "        \"latitude\": \"N/A\",\n",
    "        \"longitude\": \"N/A\",\n",
    "        \"description\": \"N/A\",\n",
    "        \"check_in_time\": \"N/A\",\n",
    "        \"check_out_time\": \"N/A\",\n",
    "        \"children_policies\": \"N/A\",\n",
    "        \"cot_extra_bed_policies\": {}, \n",
    "        \"age_restriction\": \"N/A\",\n",
    "        \"payment_methods\": {},  \n",
    "        \"smoking_policy\": \"N/A\",\n",
    "        \"pets_policy\": \"N/A\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # Get page source\n",
    "        page_source = driver.page_source\n",
    "\n",
    "        # Extract latitude, longitude, and hotel_id using regex\n",
    "        lat_match = re.search(r\"b_map_center_latitude\\s*=\\s*([\\d.]+);\", page_source)\n",
    "        lon_match = re.search(r\"b_map_center_longitude\\s*=\\s*([\\d.]+);\", page_source)\n",
    "        hotel_id_match = re.search(r\"b_hotel_id\\s*=\\s*'(\\d+)';\", page_source)\n",
    "\n",
    "        property_details[\"latitude\"] = lat_match.group(1) if lat_match else \"N/A\"\n",
    "        property_details[\"longitude\"] = lon_match.group(1) if lon_match else \"N/A\"\n",
    "        property_details[\"hotel_id\"] = hotel_id_match.group(1) if hotel_id_match else \"N/A\"\n",
    "\n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "\n",
    "    # Extract Best Review Score Label\n",
    "    try:\n",
    "        property_details[\"best_review_score_label\"] = driver.find_element(By.XPATH, '//p[@class=\"best-review-score-label\"]').text.strip()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # **Extract Best Review Score Rating\n",
    "    try:\n",
    "        property_details[\"best_review_score_rating\"] = driver.find_element(By.XPATH, '//span[@class=\"review-score-badge\"]').text.strip()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # **Extract Address**\n",
    "    try:\n",
    "        address_elem = driver.find_element(By.XPATH, \"(//div[@data-testid='PropertyHeaderAddressDesktop-wrapper']//div[@tabindex='0'])[1]\").text.strip()\n",
    "        cleaned_address = [line.strip() for line in address_elem.split(\"\\n\") if line.strip()][0]\n",
    "        property_details[\"address\"] = cleaned_address\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "    # **Extract Description**\n",
    "    try:\n",
    "        property_details[\"description\"] = driver.find_element(By.XPATH, \"//p[@data-testid='property-description']\").text.strip()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # **Extract Check-in Time**\n",
    "    try:\n",
    "        checkin_label = driver.find_element(By.XPATH, \"//div[contains(@class, 'e1eebb6a1e') and contains(text(), 'Check-in')]\")\n",
    "        checkin_time_elem = checkin_label.find_element(By.XPATH, \"./ancestor::div[contains(@class, 'c6e1dbf31b')]/following-sibling::div[contains(@class, 'f565581f7e')]/div[contains(@class, 'a53cbfa6de')]\")\n",
    "        property_details[\"check_in_time\"] = checkin_time_elem.text.strip()\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # **Extract Check-out Time**\n",
    "    try:\n",
    "        checkout_label = driver.find_element(By.XPATH, \"//div[contains(@class, 'e1eebb6a1e') and contains(text(), 'Check-out')]\")\n",
    "        checkout_time_elem = checkout_label.find_element(By.XPATH, \"./ancestor::div[contains(@class, 'c6e1dbf31b')]/following-sibling::div[contains(@class, 'f565581f7e')]/div[contains(@class, 'a53cbfa6de')]\")\n",
    "        property_details[\"check_out_time\"] = checkout_time_elem.text.strip()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # **Extract Children Policies**\n",
    "    try:\n",
    "        property_details[\"children_policies\"] = \" \".join(\n",
    "            p.text.strip() for p in driver.find_elements(By.XPATH, \"//div[@class='c64ba425c8']/p\")\n",
    "        )\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # **Extract Age Restriction** \n",
    "    try:\n",
    "        age_restriction_label = driver.find_element(By.XPATH, \"//div[contains(@class, 'e1eebb6a1e') and (contains(text(), 'Age restriction') or contains(text(), 'age restriction'))]\")\n",
    "        age_restriction_elem = age_restriction_label.find_element(By.XPATH, \"./ancestor::div[contains(@class, 'c6e1dbf31b')]/following-sibling::div[contains(@class, 'f565581f7e')]/div[contains(@class, 'a53cbfa6de')]\")\n",
    "        property_details[\"age_restriction\"] = age_restriction_elem.text.strip()\n",
    "    except:\n",
    "        pass\n",
    "     \n",
    "    # **Call functions - Review scores, payment methods, cot and extra bed policies** \n",
    "    property_details[\"review_scores\"] = scrape_review_scores(driver)\n",
    "    property_details[\"payment_methods\"] = scrape_payment_methods(driver)\n",
    "    property_details[\"cot_extra_bed_policies\"] = scrape_cot_extra_bed_policies(driver)\n",
    "    \n",
    "    \n",
    "    # **Extract Smoking Policy** \n",
    "    try:\n",
    "        smoking_label = driver.find_element(By.XPATH, \"//div[contains(@class, 'e1eebb6a1e') and contains(text(), 'Smoking')]\")\n",
    "        smoking_elem = smoking_label.find_element(By.XPATH, \"./ancestor::div[contains(@class, 'c6e1dbf31b')]/following-sibling::div[contains(@class, 'f565581f7e')]/div[contains(@class, 'a53cbfa6de')]\")\n",
    "        property_details[\"smoking_policy\"] = smoking_elem.text.strip()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # **Extract Pets** \n",
    "    try:\n",
    "        pets_label = driver.find_element(By.XPATH, \"//div[contains(@class, 'e1eebb6a1e') and contains(text(), 'Pets')]\")\n",
    "        pets_elem = pets_label.find_element(By.XPATH, \"./ancestor::div[contains(@class, 'c6e1dbf31b')]/following-sibling::div[contains(@class, 'f565581f7e')]/div[contains(@class, 'a53cbfa6de')]\")\n",
    "        property_details[\"pets_policy\"] = pets_elem.text.strip()\n",
    "    except:\n",
    "        pass  \n",
    "\n",
    "    \n",
    "    return property_details\n",
    "\n",
    "def scrape_room_details(driver):\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    rooms = []\n",
    "\n",
    "    # Find all room blocks\n",
    "    room_elements = driver.find_elements(By.XPATH, '//td[contains(@class, \"hprt-table-cell-roomtype\")]')\n",
    "\n",
    "    for room in room_elements:\n",
    "        try:\n",
    "            # Extract Room Name\n",
    "            room_name = room.find_element(By.XPATH, './/a[contains(@class, \"hprt-roomtype-link\")]').text.strip()\n",
    "\n",
    "            # Extract Bed Types (concatenating multiple bed types if present)\n",
    "            bed_elements = room.find_elements(By.XPATH, './/ul[contains(@class, \"rt-bed-types\")]//li')\n",
    "            bed_types = \", \".join([bed.text.strip() for bed in bed_elements])\n",
    "\n",
    "            # Check if \"Free cot available on request\" exists\n",
    "            try:\n",
    "                room.find_element(By.XPATH, './/span[contains(text(), \"Free cot available on request\")]')\n",
    "                free_cot = \"Yes\"\n",
    "            except:\n",
    "                free_cot = \"No\"\n",
    "\n",
    "            # Extract Room Description\n",
    "            try:\n",
    "                room_description = room.find_element(By.XPATH, './/p[contains(@class, \"short-room-desc\")]').text.strip()\n",
    "            except:\n",
    "                room_description = \"N/A\"\n",
    "\n",
    "            # Extract Room Size\n",
    "            try:\n",
    "                room_size = room.find_element(By.XPATH, './/div[@data-name-en=\"room size\"]').text.strip()\n",
    "            except:\n",
    "                room_size = \"N/A\"\n",
    "\n",
    "           # Extract Room Highlights (excluding room size)\n",
    "            try:\n",
    "                highlights = [\n",
    "                    elem.text.strip() for elem in room.find_elements(\n",
    "                        By.XPATH, './/div[contains(@class, \"hprt-facilities-facility\") and not(@data-name-en=\"room size\")]//span'\n",
    "                    )\n",
    "                ]\n",
    "            except:\n",
    "                highlights = []\n",
    "\n",
    "            # Extract Other Facilities (e.g., Free Toiletries, Bathrobe)\n",
    "            try:\n",
    "                other_facilities = [\n",
    "                    elem.text.strip() for elem in room.find_elements(\n",
    "                        By.XPATH, './/ul[contains(@class, \"hprt-facilities-others\")]//span'\n",
    "                    )\n",
    "                ]\n",
    "            except:\n",
    "                other_facilities = []\n",
    "\n",
    "            # Combine Highlights & Other Facilities\n",
    "            all_amenities = list(set(highlights + other_facilities))  # Remove duplicates\n",
    "            room_facilities = \", \".join(all_amenities) if all_amenities else \"No facilities listed\"\n",
    "\n",
    "            # Append to results list\n",
    "            rooms.append({\n",
    "                \"Room Name\": room_name,\n",
    "                \"Bed Types\": bed_types,\n",
    "                \"Free Cot Available\": free_cot,\n",
    "                \"Room Description\": room_description,\n",
    "                \"Room Size\": room_size,\n",
    "                \"Room Highlights & Facilities\": room_facilities\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing room: {e}\")\n",
    "\n",
    "    return rooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_hotel_surroundings(driver):\n",
    "\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    surroundings = {}\n",
    "\n",
    "    try:\n",
    "        wait.until(EC.presence_of_element_located((By.ID, \"surroundings_block\")))\n",
    "    except:\n",
    "        return {}\n",
    "\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(2)\n",
    "\n",
    "    category_elements = driver.find_elements(By.XPATH, \"//div[@data-testid='poi-block']\")\n",
    "\n",
    "    for category_elem in category_elements:\n",
    "        try:\n",
    "            # Extract category name (e.g., \"What's nearby\", \"Top attractions\")\n",
    "            category = category_elem.find_element(By.XPATH, \".//div[contains(@class, 'e1eebb6a1e')]\").text.strip()\n",
    "            places = category_elem.find_elements(By.XPATH, \".//ul[@data-testid='poi-block-list']/li\")\n",
    "\n",
    "            place_list = []\n",
    "            for place in places:\n",
    "                category_label = \"\"\n",
    "                try:\n",
    "                    category_label = place.find_element(By.XPATH, \".//span[contains(@class, 'b6f930dcc9')]\").text.strip()\n",
    "                except:\n",
    "                    pass  # Ignore if category label not found\n",
    "\n",
    "                # Extract place name\n",
    "                full_text = place.find_element(By.XPATH, \".//div[contains(@class, 'dc5041d860')]\").text.strip()\n",
    "                name = full_text.replace(category_label, \"\").strip() if category_label else full_text\n",
    "\n",
    "                # Extract distance\n",
    "                try:\n",
    "                    distance = place.find_element(By.XPATH, \".//div[contains(@class, 'e018b15ee8')]//div\").text.strip()\n",
    "                except:\n",
    "                    distance = \"\"\n",
    "\n",
    "                # Ensure valid data\n",
    "                if name and distance:\n",
    "                    place_list.append({\"name\": name, \"category\": category_label if category_label else None, \"distance\": distance})\n",
    "\n",
    "            # Only add non-empty categories\n",
    "            if place_list:\n",
    "                surroundings[category] = place_list\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error scraping category: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    # Return properly structured JSON\n",
    "    return surroundings\n",
    "\n",
    "\n",
    "def scrape_hotel_facilities(driver):\n",
    "\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    facilities = {}\n",
    "\n",
    "    # Ensure facilities section is loaded\n",
    "    try:\n",
    "        wait.until(EC.presence_of_element_located((By.ID, \"hp_facilities_box\")))\n",
    "    except:\n",
    "        return {}\n",
    "\n",
    "    # Scroll down to ensure elements are loaded\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(2)  # Allow time for elements to load\n",
    "\n",
    "    # Locate all categories\n",
    "    try:\n",
    "        category_elements = wait.until(\n",
    "            EC.presence_of_all_elements_located((By.XPATH, \"//section[@id='hp_facilities_box']//h3\"))\n",
    "        )\n",
    "    except:\n",
    "        return {}\n",
    "\n",
    "    for i in range(len(category_elements)):  # Use index to re-fetch elements\n",
    "        try:\n",
    "            # Re-fetch category elements before each iteration\n",
    "            category_elements = driver.find_elements(By.XPATH, \"//section[@id='hp_facilities_box']//h3\")\n",
    "            category_elem = category_elements[i]  # Get fresh reference\n",
    "            \n",
    "            category = category_elem.text.strip()\n",
    "\n",
    "            # Extract the facilities under this category\n",
    "            try:\n",
    "                items = WebDriverWait(driver, 5).until(\n",
    "                    EC.presence_of_all_elements_located((By.XPATH, f\"(//section[@id='hp_facilities_box']//h3)[{i+1}]/following-sibling::ul[1]/li\"))\n",
    "                )\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            facility_list = [item.text.strip() for item in items if item.text.strip()]\n",
    "            if facility_list:\n",
    "                facilities[category] = facility_list\n",
    "\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    return facilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping: A Hotel Joo Chiat\n",
      "Scraping: M Social Singapore\n",
      "Scraping: KINN Studios\n",
      "Scraping: Park View Hotel\n",
      "Scraping: ibis budget Singapore Crystal\n",
      "Scraping: Park Avenue Changi\n",
      "Scraping: ibis budget Singapore Ametrine\n",
      "Scraping: ibis budget Singapore Emerald\n",
      "Scraping: ibis budget Singapore Ruby\n",
      "Scraping: ibis budget Singapore Bugis\n",
      "Scraping: Vibe Hotel Singapore Orchard\n",
      "Scraping: Rendezvous Hotel Singapore by Far East Hospitality\n",
      "Scraping: Travelodge Harbourfront Singapore\n",
      "Scraping: Hotel Grand Central\n",
      "Scraping: Holiday Inn Express Singapore Katong by IHG\n",
      "Scraping: Hotel 1900 Chinatown\n",
      "Scraping: Champion Hotel City\n",
      "Scraping: Mercure Singapore Bugis\n",
      "Scraping: JEN Singapore Orchardgateway by Shangri-La\n",
      "Scraping: Harbour Ville Hotel\n",
      "Scraping: Aerotel Singapore - Transit Hotel in Terminal 1\n",
      "Scraping: ibis budget Singapore Joo Chiat\n",
      "Scraping: Marina Bay Sands\n",
      "Scraping: 30 Bencoolen\n",
      "Scraping: CapsulePod@Aljunied\n",
      "Scraping: Orchard Rendezvous Hotel by Far East Hospitality\n",
      "Scraping: Hotel Traveltine\n",
      "Scraping: Mercure Singapore Tyrwhitt\n",
      "Scraping: PARKROYAL on Beach Road, Singapore\n",
      "Scraping: Oasia Hotel Downtown, Singapore by Far East Hospitality\n",
      "Scraping: lyf Funan Singapore\n",
      "Scraping: InterContinental Singapore by IHG\n",
      "Scraping: Holiday Inn Express Singapore Serangoon by IHG\n",
      "Scraping: Grand Mercure Singapore Roxy\n",
      "Scraping: Ibis Singapore Novena\n",
      "Scraping: PARKROYAL COLLECTION Marina Bay, Singapore\n",
      "Scraping: Holiday Inn Singapore Atrium by IHG\n",
      "Scraping: Capri by Fraser China Square, Singapore\n",
      "Scraping: Ibis Singapore on Bencoolen - Newly Renovated\n",
      "Scraping: Carlton City Hotel Singapore\n",
      "Scraping: voco Orchard Singapore by IHG\n",
      "Scraping: Naumi Hotel Singapore\n",
      "Scraping: Hotel Indigo Singapore Katong by IHG\n",
      "Scraping: Holiday Inn Express & Suites Singapore Novena by IHG\n",
      "Scraping: The Scarlet Singapore\n",
      "Scraping: Dao by Dorsett AMTD Singapore\n",
      "Scraping: Pullman Singapore Orchard\n",
      "Scraping: Mercure ICON Singapore City Centre\n",
      "Scraping: PARKROYAL COLLECTION Pickering, Singapore\n",
      "Scraping: The Serangoon House, a Tribute Portfolio Hotel Singapore\n",
      "Scraping: Aqueen Hotel Paya Lebar\n",
      "Scraping: lyf Bugis Singapore managed by The Ascott Ltd\n",
      "Scraping: Novotel Singapore On Stevens\n",
      "Scraping: Oasia Hotel Novena, Singapore by Far East Hospitality\n",
      "Scraping: Sheraton Towers Singapore Hotel\n",
      "Scraping: Pullman Singapore Hill Street\n",
      "Scraping: ibis Styles Singapore Albert\n",
      "Scraping: Goodwood Park Hotel\n",
      "Scraping: Village Hotel Katong by Far East Hospitality\n",
      "Scraping: YOTEL Singapore Orchard Road\n",
      "Scraping: The Sultan\n",
      "Scraping: Aloft Singapore Novena\n",
      "Scraping: Hotel Royal Queens\n",
      "Scraping: Sofitel Singapore Sentosa Resort & Spa\n",
      "Scraping: Village Hotel Bugis by Far East Hospitality\n",
      "Scraping: AMOY by Far East Hospitality\n",
      "Scraping: Village Hotel Changi by Far East Hospitality\n",
      "Scraping: InterContinental Singapore Robertson Quay by IHG\n",
      "Scraping: QT Singapore\n",
      "Scraping: Four Seasons Hotel Singapore\n",
      "Scraping: Dorsett Singapore\n",
      "Scraping: The Outpost Hotel Sentosa by Far East Hospitality\n",
      "Scraping: Hilton Garden Inn Singapore Serangoon\n",
      "Scraping: Conrad Centennial Singapore\n",
      "Scraping: The Seacare Hotel\n",
      "Scraping: Citadines Science Park Singapore\n",
      "Scraping: Ascott Orchard Singapore\n",
      "Scraping: Conrad Singapore Orchard\n",
      "Scraping: Four Points by Sheraton Singapore, Riverview\n",
      "Scraping: Rest Bugis Hotel\n",
      "Scraping: Dorsett Changi City Singapore\n",
      "Scraping: Pan Pacific Orchard\n",
      "Scraping: ibis budget Singapore West Coast\n",
      "Scraping: Grand Park City Hall\n",
      "Scraping: Citadines Connect Rochester Singapore\n",
      "Scraping: Rest Chinatown Hotel\n",
      "Scraping: Oasia Resort Sentosa by Far East Hospitality\n",
      "Scraping: D'Hotel Singapore managed by The Ascott Limited\n",
      "Scraping: The Fullerton Bay Hotel Singapore\n",
      "Scraping: Quincy Hotel Singapore by Far East Hospitality\n",
      "Scraping: Hotel NuVe Urbane\n",
      "Scraping: Hotel Boss\n",
      "Scraping: Andaz Singapore, By Hyatt\n",
      "Scraping: Amara Sanctuary Resort Sentosa\n",
      "Scraping: D'Resort @ Downtown East\n",
      "Scraping: D'Nova Hotel Bugis\n",
      "Scraping: Park Regis by Prince Singapore - Newly Renovated\n",
      "Scraping: Amara Singapore - Newly Renovated\n",
      "Scraping: The Capitol Kempinski Hotel Singapore\n",
      "Scraping: The Standard, Singapore\n",
      "Scraping: Sofitel Singapore City Centre\n",
      "Scraping: Village Hotel Albert Court by Far East Hospitality\n",
      "Scraping: Summer View Hotel\n",
      "Scraping: Grand Copthorne Waterfront\n",
      "Scraping: Furama RiverFront\n",
      "Scraping: Ibis Styles Singapore On Macpherson\n",
      "Scraping: Studio M Hotel\n",
      "Scraping: The Clan Hotel Singapore by Far East Hospitality\n",
      "Scraping: The Vagabond Club, a Tribute Portfolio Hotel Singapore\n",
      "Scraping: Duxton Reserve, a Marriott Autograph Collection Hotel Singapore\n",
      "Scraping: Mandarin Oriental, Singapore\n",
      "Scraping: Hotel 81 Premier Princess\n",
      "Scraping: M Hotel Singapore City Centre\n",
      "Scraping: Owen House by Habyt\n",
      "Scraping: Holiday Inn Express Singapore Orchard Road by IHG\n",
      "Scraping: Value Hotel Thomson\n",
      "Scraping: Raffles Singapore\n",
      "Scraping: JEN Singapore Tanglin by Shangri-La\n",
      "Scraping: Swissotel The Stamford Singapore\n",
      "Scraping: V Hotel Bencoolen\n",
      "Scraping: Fairmont Singapore\n",
      "Scraping: Strand Hotel\n",
      "Scraping: Hotel Mi Bencoolen\n",
      "Scraping: The Barracks Hotel Sentosa by Far East Hospitality\n",
      "Scraping: Furama City Centre\n",
      "Scraping: Fragrance Hotel - Balestier\n",
      "Scraping: Hotel 81 Dickson\n",
      "Scraping: Hotel 81 Orchid\n",
      "Scraping: V Hotel Lavender\n",
      "Scraping: Oxford Hotel\n",
      "Scraping: The Ritz-Carlton, Millenia Singapore\n",
      "Scraping: Carlton Hotel Singapore\n",
      "Scraping: ibis budget Singapore Selegie\n",
      "Scraping: Shangri-La Singapore\n",
      "Scraping: Hotel 81 Premier Star\n",
      "Scraping: Hotel 81 Palace - NEWLY RENOVATED\n",
      "Scraping: D'Nova Hotel Kallang\n",
      "Scraping: Ambassador Transit Hotel - Terminal 3\n",
      "Scraping: Orchard Hotel Singapore\n",
      "Scraping: Spacepod@hive\n",
      "Scraping: Hotel 81 Gold\n",
      "Scraping: 7 Wonders Hostel @ Boat Quay\n",
      "Scraping: Bliss Hotel Singapore\n",
      "Scraping: Hotel Mi Rochor\n",
      "Scraping: Hotel Classic by Venue\n",
      "Scraping: ibis budget Singapore Gold\n",
      "Scraping: Hotel 81 Cosy\n",
      "Scraping: Hotel 81 Changi\n",
      "Scraping: Hotel 81 Heritage\n",
      "Scraping: ibis budget Singapore Sapphire\n",
      "Scraping: Ambassador Transit Hotel - Terminal 2\n",
      "Scraping: The Quay Hotel\n",
      "Scraping: Hotel 81 Rochor\n",
      "Scraping: KēSa House, The Unlimited Collection managed by The Ascott Limited\n",
      "Scraping: One Farrer Hotel\n",
      "Scraping: Spacepod@SG\n",
      "Scraping: Venue Hotel The Lily\n",
      "Scraping: Wanderlust, The Unlimited Collection managed by The Ascott Limited\n",
      "Scraping: hipstercity hostel\n",
      "Scraping: Spacepod@com\n",
      "Scraping: Citadines Connect City Centre Singapore\n",
      "Scraping: York Hotel\n",
      "Scraping: Hotel 81 Tristar\n",
      "Scraping: Republic of Singapore Yacht Club\n",
      "Scraping: Wink at Mosque Street\n",
      "Scraping: YMCA One Orchard\n",
      "Scraping: Ji Hotel Orchard Singapore\n",
      "Scraping: Wyndham Singapore Hotel\n",
      "Scraping: Hotel 81 Sakura\n",
      "Scraping: HOTEL JJH - newly opened near BUGIS\n",
      "Scraping: Backpacker Cozy Corner Guesthouse\n",
      "Scraping: Fragrance Hotel - Oasis\n",
      "Scraping: ONE15 Marina Sentosa Cove Singapore\n",
      "Scraping: Hotel Supreme\n",
      "Scraping: Hotel 81 Chinatown\n",
      "Scraping: Hotel 81 Bugis\n",
      "Scraping: Hotel 81 Lavender\n",
      "Scraping: Lloyd's Inn\n",
      "Scraping: The St. Regis Singapore\n",
      "Scraping: Hotel 81 Premier Hollywood\n",
      "Scraping: Hotel 81 Osaka\n",
      "Scraping: Habyt Studios Kallang\n",
      "Scraping: Wink at McCallum Street\n",
      "Scraping: ibis budget Singapore Mount Faber\n",
      "Scraping: Value Hotel Balestier\n",
      "Scraping: Resorts World Sentosa - Equarius Hotel\n",
      "Scraping: Tai Hoe Hotel\n",
      "Scraping: STORIES Joo Chiat, a Hotel by Cove - Paya Lebar, Singapore - NEWLY RENOVATED\n",
      "Scraping: K Hotel 8\n",
      "Scraping: Resorts World Sentosa - Hotel Michael\n",
      "Scraping: Hotel 81 Joy\n",
      "Scraping: Fragrance Hotel - Rose\n",
      "Scraping: Siloso Beach Resort - Sentosa\n",
      "Scraping: Arcadia Hotel\n",
      "Scraping: Hotel 81 Selegie\n",
      "Scraping: Hotel 81 Lucky\n",
      "Scraping: Hotel Clover The Arts\n",
      "Scraping: Singapore Marriott Tang Plaza Hotel\n",
      "Scraping: The Snooze Hotel Marine Parade\n",
      "Scraping: Hotel 81 Kovan\n",
      "Scraping: Jyu Capsule Hotel\n",
      "Scraping: Ascott Raffles Place Singapore\n",
      "Scraping: Q Loft Hotels at Bedok\n",
      "Scraping: Hotel 81 Elegance\n",
      "Scraping: Hotel Bencoolen at Hong Kong Street\n",
      "Scraping: Ann Siang House, The Unlimited Collection managed by The Ascott Limited\n",
      "Scraping: CUBE Family Boutique Capsule Hotel at Chinatown\n",
      "Scraping: Value Hotel Nice\n",
      "Scraping: Haising Hotel\n",
      "Scraping: Dream Lodge\n",
      "Scraping: Orchid Country Club\n",
      "Scraping: Code Hostel at Kampong Glam\n",
      "Scraping: Hotel Chancellor@Orchard\n",
      "Scraping: Copthorne King's Hotel Singapore\n",
      "Scraping: Hotel Yan\n",
      "Scraping: Venue Hotel\n",
      "Scraping: Hotel Mono\n",
      "Scraping: La Mode (Sophia) Hotel\n",
      "Scraping: Artyzen Singapore\n",
      "Scraping: Maxwell Reserve, a Marriott Autograph Collection Hotel Singapore\n",
      "Scraping: New Cape Inn\n",
      "Scraping: Changi Cove\n",
      "Scraping: Concorde Hotel Singapore\n",
      "Scraping: Resorts World Sentosa - Hotel Ora\n",
      "Scraping: J8 Hotel\n",
      "Scraping: Novotel Singapore on Kitchener\n",
      "Scraping: Genting Hotel Jurong\n",
      "Scraping: Perak Hotel\n",
      "Scraping: Momentus Hotel Alexandra\n",
      "Scraping: Hotel Grand Pacific\n",
      "Scraping: CUBE Boutique Capsule Hotel at Chinatown\n",
      "Scraping: Rucksack Inn Tyrwhitt Road\n",
      "Scraping: Fragrance Hotel - Classic\n",
      "Scraping: Victoria Hotel a NuVe Group Collection\n",
      "Scraping: 7 Wonders Hostel at Upper Dickson\n",
      "Scraping: KINN Habitat\n",
      "Scraping: Hotel 81 Geylang\n",
      "Scraping: BEAT. Sports Hostel\n",
      "Scraping: Hotel Calmo Bugis\n",
      "Scraping: 21 Carpenter, Singapore, a Member of Design Hotels\n",
      "Scraping: YWCA Fort Canning\n",
      "Scraping: Hotel Calmo Chinatown\n",
      "Scraping: Classique Hotel\n",
      "Scraping: Nostalgia Hotel\n",
      "Scraping: ISA Hotel Amber Road\n",
      "Scraping: Park Avenue Rochester\n",
      "Scraping: Wink at Perak Road\n",
      "Scraping: Jayleen 1918\n",
      "Scraping: Hotel 81 Fuji\n",
      "Scraping: The Pod at Beach Road Boutique Capsule Hotel\n",
      "Scraping: Courtyard by Marriott Singapore Novena\n",
      "Scraping: RELC International Hotel\n",
      "Scraping: BEAT Arts Hostel at Chinatown\n",
      "Scraping: The Quay Hotel West Coast\n",
      "Scraping: Habyt Studios at Novena\n",
      "Scraping: Metropolitan YMCA Singapore\n",
      "Scraping: Hotel 81 Balestier\n",
      "Scraping: Hotel Clover 7\n",
      "Scraping: Fragrance Hotel - Lavender\n",
      "Scraping: Hotel NuVe Elements\n",
      "Scraping: K Hotel 12\n",
      "Scraping: Wink at Upper Cross Street\n",
      "Scraping: BEAT. Capsule Hostel @ Boat Quay\n",
      "Scraping: Heritage Collection on Chinatown - Mobile App Check-In\n",
      "Scraping: Link Hotel Singapore\n",
      "Scraping: ST Signature Bugis Beach, SHORT OVERNIGHT, 8 Hours, 11PM-7AM\n",
      "Scraping: JW Marriott Hotel Singapore South Beach\n",
      "Scraping: Hotel Clover 769 North Bridge Road\n",
      "Scraping: Code Hostel at Lavender\n",
      "Scraping: five6 Hotel Splendour\n",
      "Scraping: The Southbridge Hotel\n",
      "Scraping: The Snooze Hotel at Bugis\n",
      "Scraping: Amrise Hotel Kitchener\n",
      "Scraping: Jayleen Clarke Quay Hotel\n",
      "Scraping: Hotel NuVe Heritage\n",
      "Scraping: RadZone Hostel\n",
      "Scraping: Fragrance Hotel - Kovan\n",
      "Scraping: Resorts World Sentosa - Equarius Villas\n",
      "Scraping: International Service Apartments at Raeburn Park\n",
      "Scraping: ST Signature Bugis Middle\n",
      "Scraping: ST Signature Tanjong Pagar, SHORT OVERNIGHT, 12 hours, 8PM-8AM\n",
      "Scraping: Dash Living Rochor\n",
      "Scraping: Hotel 1900 Express Chinatown\n",
      "Scraping: Beverly Hotels Elements\n",
      "Scraping: Heritage Collection on Boat Quay - Quayside Wing - Mobile App Check-In\n",
      "Scraping: ST Signature Jalan Besar, SHORT OVERNIGHT, 8 Hours, 1159PM-8AM\n",
      "Scraping: Weave Suites - Midtown\n",
      "Scraping: Rucksack Inn Temple Street\n",
      "Scraping: Philip HOME stay\n",
      "Scraping: Kam Leng Hotel\n",
      "Scraping: Cube Social Boutique Capsule Hotel at Boat Quay\n",
      "Scraping: A Hotel Bugis\n",
      "Scraping: ST Signature Bugis Beach, SHORT OVERNIGHT, 12 Hours, check in 7PM or 9PM\n",
      "Scraping: Hotel Bencoolen Singapore\n",
      "Scraping: CUBE Boutique Capsule Hotel at Kampong Glam\n",
      "Scraping: The Bus Collective\n",
      "Scraping: Labrador Villa\n",
      "Scraping: ST Signature Tanjong Pagar, DAYUSE, 8 hours, 10AM-6PM\n",
      "Scraping: Fragrance Hotel - Viva\n",
      "Scraping: Hotel Conforto\n",
      "Scraping: Aqueen Prestige Hotel Lavender\n",
      "Scraping: Kranji Sanctuary Resort\n",
      "Scraping: Santa Grand Hotel East Coast a NuVe Group Collection\n",
      "Scraping: Claude Hotel\n",
      "Scraping: MET A Space Pod at Arab Street\n",
      "Scraping: A Hotel Desker\n",
      "Scraping: Fragrance Hotel - Ocean View\n",
      "Scraping: Aqueen Prestige Hotel Jalan Besar\n",
      "Scraping: Arton Boutique Hotel\n",
      "Scraping: ST Signature Bugis Beach, DAYUSE, 8-9 Hours, check in 8AM or 11AM\n",
      "Scraping: The Westin Singapore\n",
      "Scraping: The Singapore EDITION\n",
      "Scraping: The Amazing Inn\n",
      "Scraping: Arena eSports Hotel @ Bugis Village\n",
      "Scraping: The Daulat by Hotel Calmo\n",
      "Scraping: Hotel NuVe\n",
      "Scraping: Harbour Ville Hotel - Hamilton\n",
      "Scraping: Sandpiper Hotel Singapore\n",
      "Scraping: HOTEL JJH Aliwal\n",
      "Scraping: Capella Singapore\n",
      "Scraping: The Great Madras by Hotel Calmo\n",
      "Scraping: Garden Pod at Gardens by the Bay\n",
      "Scraping: ST Signature Bugis Middle, SHORT OVERNIGHT, 11 hours 8PM-7AM\n",
      "Scraping: K2 Guesthouse\n",
      "Scraping: Asphodel Inn\n",
      "Scraping: 7 Wonders Boutique Capsule\n",
      "Scraping: A Hotel Bugis, 11Hrs, Stay From 8PM To 9AM\n",
      "Scraping: K Hotel 1515\n",
      "Scraping: ST Signature Jalan Besar, DAYUSE, 5 Hours, 10AM-3PM\n",
      "Scraping: Arena eSports @ Orchard\n",
      "Scraping: Beary Best! Hostel Chinatown\n",
      "Scraping: Amrise Hotel Kitchener, Check In 9PM, Check Out 8AM\n",
      "Scraping: Golden Star Hotel\n",
      "Scraping: SENG WAH HOTEL\n",
      "Scraping: K Hotel 14\n",
      "Scraping: ST Signature Bugis Beach\n",
      "Scraping: ST Signature Bugis Beach, DAYUSE, 5 Hours, 4PM-9PM\n",
      "Scraping: A Hotel Dickson\n",
      "Scraping: New Orchid Hotel\n",
      "Scraping: ST Signature Jalan Besar, SHORT OVERNIGHT, 13 Hours, 6PM-7AM\n",
      "Scraping: Noble Hotel Express, Check in 10PM, Check out 9AM\n",
      "Scraping: ST Signature Jalan Besar, DAYUSE, 7 Hours, 9AM-4PM\n",
      "Scraping: ST Signature Jalan Besar, DAYUSE, 5 Hours, 5PM-10PM\n",
      "Scraping: ST Signature Tanjong Pagar\n",
      "Scraping: Dream Chaser Boutique Capsule Hotel\n",
      "Scraping: Amrise Hotel, Check in at 10PM, Check out at 9AM\n",
      "Scraping: Hi Hotel Dot\n",
      "Scraping: The Noble Hotel\n",
      "Scraping: ST Signature Jalan Besar\n",
      "Scraping: Check-Inn at Little India\n",
      "Scraping: River City Inn\n",
      "Scraping: Hi Hotel Dot, 11Hrs, Stay from 10PM to 9AM\n",
      "Scraping: Bluewaters Female-Only Hostel\n",
      "Scraping: ST Signature Bugis Beach, DAYUSE, 5 Hours, 9AM-2PM\n",
      "Scraping: Shipping Container Hotel at Haw Par Villa GoogleMap Address 27 Zehnder Road Taxi and cars can only enter via Zehnder Road\n",
      "Scraping: Resorts World Sentosa - Crockfords Tower\n",
      "Scraping: Bluewaters Pods 38 Hongkong St\n",
      "Scraping: Novena Serviced Apartment Deluxe One bedroom\n",
      "Scraping: Futura Boutique Hostel\n",
      "Scraping: Meadows Hostel\n",
      "Scraping: Amrise Hotel\n",
      "Scraping: Duke Living\n",
      "Scraping: Social-Inn Norris Road Apt\n",
      "Scraping: RR Cozy Room Suite\n",
      "Scraping: Coliwoo Hotel Pasir Panjang - CoLiving\n",
      "Scraping: A Hotel Dickson, Stay From 9PM To 8AM\n",
      "Scraping: ST Signature Chinatown\n",
      "Scraping: Shipping Container Hotel At One-north\n",
      "Scraping: The Warehouse Hotel, Singapore, a Member of Design Hotels\n",
      "Scraping: Snooze Inn @Dunlop Street\n",
      "Scraping: Coller Chinatown\n",
      "Scraping: A Hotel Joo Chiat, Stay From 7PM to 9AM\n",
      "Scraping: K2 Guesthouse Central\n",
      "Scraping: A Desker Hotel, Stay From 6PM to 9AM\n",
      "Scraping: Glamping Kaki - Large Bell Tent\n",
      "Scraping: Downtown Apartment\n",
      "Scraping: Single Sharing Room and Short Hours Stay at Sandpiper Hotel\n",
      "Scraping: 36 club st residence\n",
      "Scraping: ST Signature Bugis Middle,DAYUSE,9 hours 9AM-6PM\n",
      "Scraping: The Room @ Bugis\n",
      "Scraping: Ultra Luxury Family House\n",
      "Scraping: Raffles Sentosa Singapore\n",
      "Scraping: Bart house\n",
      "Scraping: Philip Hotel Balestier\n",
      "Scraping: Campbell Inn\n",
      "Scraping: Philip Hotel at Little India\n",
      "Scraping: MASTER BEDROOM SUITE\n",
      "Scraping: Glamping Kaki - Medium Bell Tent\n",
      "Scraping: KINN Capsule\n",
      "Scraping: Atelier\n",
      "Scraping: Ambassador Transit Lounge Terminal 3\n",
      "Scraping: Ambassador Transit Lounge Terminal 2\n",
      "Scraping: The Hive Singapore Hostel\n",
      "Scraping: The Bohemian\n",
      "Scraping: Betel Box Backpackers Hostel\n",
      "Scraping: Beary Best! Hostel Kampong Glam\n",
      "Scraping: CSW Hostel\n",
      "Scraping: Royal Lodge @ Pagoda Street\n",
      "Scraping: Checkers Hostel\n",
      "Scraping: Dash Living on Mackenzie\n",
      "Scraping: THE ROOM Capsule Hotel\n",
      "Scraping: K Space Inn 14\n",
      "Scraping: Atlantis Pods @ Little India\n",
      "Scraping: Bluewaters Collab Quarters\n",
      "Scraping: K Space Inn 569\n",
      "Scraping: Gusti Bed & Breakfast Singapore\n",
      "Scraping: POTATO Boutique Hostel\n",
      "Scraping: Pan Pacific Singapore\n",
      "Scraping: Dusit Thani Laguna Singapore\n",
      "Scraping: Mondrian Singapore Duxton\n",
      "Scraping: COMO Metropolitan Singapore\n",
      "Scraping: YOTELAIR Singapore Changi Airport Landside\n",
      "Scraping: The Center of Singapore; China Town\n",
      "Scraping: Hotel Royal\n",
      "Scraping: Mandai Rainforest Resort by Banyan Tree\n",
      "Scraping: ooo For Ladies Only ooo Bukit Timah master room\n",
      "Scraping: House of Melissa Boutique Farmstay\n",
      "Scraping: The Fullerton Hotel Singapore\n",
      "Scraping: The Robertson House by The Crest Collection\n",
      "Scraping: Citadines Rochor Singapore\n",
      "Scraping: W Singapore - Sentosa Cove\n",
      "Scraping: Heritage Collection on Pagoda - Mobile App Check-In\n",
      "Scraping: Crowne Plaza Changi Airport by IHG\n",
      "Scraping: Holiday Inn Express Singapore Clarke Quay by IHG\n",
      "Scraping: ibis budget Singapore Clarke Quay\n",
      "Scraping: Shangri-La Rasa Sentosa, Singapore\n",
      "Scraping: Royal Plaza on Scotts\n",
      "Scraping: Mercure Singapore On Stevens\n",
      "Scraping: The Inn at Temple Street\n",
      "Scraping: Pan Pacific Serviced Suites Beach Road, Singapore\n",
      "Scraping: ibis budget Singapore Pearl\n",
      "Scraping: The Quay Hotel Little India\n",
      "Scraping: Comfy Studio 5 by Ong Realty\n",
      "Scraping: Comfy Studio 2 by Ong Realty\n",
      "Scraping: Comfy Studio 6 by Ong Realty\n",
      "Scraping: Holiday Inn Singapore Orchard City Centre by IHG\n",
      "Scraping: ibis budget Singapore Imperial\n",
      "Scraping: Paradox Singapore Merchant Court at Clarke Quay\n",
      "Scraping: Holiday Inn Singapore Little India by IHG\n",
      "Scraping: Hilton Singapore Orchard\n",
      "Scraping: Village Hotel Sentosa by Far East Hospitality\n",
      "Scraping: Hotel Faber Park Singapore - Handwritten Collection\n",
      "Scraping: Hotel Fuji\n",
      "Scraping: R Residences\n",
      "\n",
      "Scraping completed. Data saved to 'booking_property_details.csv'.\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# Scrape property details\n",
    "# --------------------------\n",
    "\n",
    "csv_filename = \"property_data.csv\"\n",
    "df = pd.read_csv(csv_filename)\n",
    "property_data = df.to_dict(orient=\"records\")\n",
    "\n",
    "# # SUBSET TO FIRST 3 RECORDS\n",
    "# property_data = property_data[:3]\n",
    "\n",
    "# 2. Initialize WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "time.sleep(2)\n",
    "\n",
    "# 3. Scrape each property\n",
    "results = []\n",
    "\n",
    "for hotel in property_data:\n",
    "    hotel_name = hotel[\"hotel_name\"]\n",
    "    hotel_url = hotel[\"hotel_url\"]\n",
    "    \n",
    "    print(f\"Scraping: {hotel_name}\")\n",
    "    \n",
    "    # Load the page\n",
    "    driver.get(hotel_url)\n",
    "    time.sleep(3)  \n",
    "    \n",
    "    property_details = scrape_property_details(driver)\n",
    "    room_details = scrape_room_details(driver)\n",
    "    surroundings = scrape_hotel_surroundings(driver)\n",
    "    facilities = scrape_hotel_facilities(driver)\n",
    "    \n",
    "    # Extract hotel_id and remove from property_details\n",
    "    hotel_id = property_details.get(\"hotel_id\", \"N/A\")  # Default to \"N/A\" if not found\n",
    "    property_details.pop(\"hotel_id\", None)\n",
    "    \n",
    "    results.append({\n",
    "        \"hotel_id\": hotel_id,\n",
    "        \"hotel_name\": hotel_name,\n",
    "        **property_details,\n",
    "        \"room_details\": room_details,\n",
    "        \"surroundings\": surroundings,\n",
    "        \"facilities\": facilities\n",
    "    })\n",
    "    \n",
    "# 5. Close the driver\n",
    "driver.quit()\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# Save to CSV\n",
    "# --------------------------\n",
    "csv_filename = \"booking_property_details.csv\"\n",
    "with open(csv_filename, \"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "    fieldnames = list(results[0].keys())  \n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(results)\n",
    "\n",
    "print(f\"\\nScraping completed. Data saved to '{csv_filename}'.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Extracting Reviews from Each Property Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import csv\n",
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def click_read_all_reviews(driver):\n",
    "    \"\"\"\n",
    "    Scrolls to and clicks the 'Read all reviews' button on a Booking.com hotel page.\n",
    "    Ensures it is only clicked once.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Wait for the button to appear in the DOM\n",
    "        read_reviews_button = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.XPATH, \"//button[@data-testid='read-all-actionable']\"))\n",
    "        )\n",
    "\n",
    "        # Scroll to the button\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView({behavior: 'smooth', block: 'center'});\", read_reviews_button)\n",
    "        time.sleep(2)  # Allow scrolling to finish\n",
    "\n",
    "        # Click the button\n",
    "        read_reviews_button.click()\n",
    "        # print(\"Successfully clicked 'Read all reviews' button.\")\n",
    "\n",
    "        # Wait for new review cards to load\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.XPATH, \"//div[@data-testid='review-card']\"))\n",
    "        )\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to click 'Read all reviews' button: {e}\")\n",
    "        \n",
    "        \n",
    "def click_next_page(driver):\n",
    "    \"\"\"\n",
    "    Clicks the 'Next page' button to load more reviews with random delays.\n",
    "    Returns True if the button was clicked, False if it's the last page.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Wait for the \"Next page\" button to be clickable\n",
    "        next_button = WebDriverWait(driver, random.uniform(3, 6)).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, \"//button[@aria-label='Next page']\"))\n",
    "        )\n",
    "\n",
    "        # Randomly delay before scrolling\n",
    "        time.sleep(random.uniform(1, 3))\n",
    "\n",
    "        # Smooth scroll to the \"Next page\" button\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView({behavior: 'smooth', block: 'center'});\", next_button)\n",
    "\n",
    "        # Random delay before clicking\n",
    "        time.sleep(random.uniform(1, 2))\n",
    "\n",
    "        # Click the \"Next page\" button\n",
    "        next_button.click()\n",
    "\n",
    "        # Wait for new reviews to load (randomized delay)\n",
    "        time.sleep(random.uniform(1, 5))\n",
    "\n",
    "        return True  # More pages exist\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"🚨 No more 'Next page' button found (last page or error): {e}\")\n",
    "        return False  # Last page reached\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_review_score(card):\n",
    "    \"\"\"Extracts the review score from a review card with proper waiting.\"\"\"\n",
    "    try:\n",
    "        # ✅ Ensure review card is in view (fixes dynamic loading issues)\n",
    "        card.location_once_scrolled_into_view\n",
    "        time.sleep(random.uniform(1, 3))  # Random delay to mimic human scrolling\n",
    "\n",
    "        # ✅ Wait for review score to appear before extracting\n",
    "        review_score_element = WebDriverWait(card, random.uniform(2, 6)).until(\n",
    "            EC.presence_of_element_located((By.XPATH, \".//div[@data-testid='review-score']//div[contains(@class, 'ac4a7896c7')]\"))\n",
    "        )\n",
    "\n",
    "        raw_score_text = review_score_element.text.strip()\n",
    "\n",
    "        # ✅ Extract only numeric score\n",
    "        match = re.search(r\"(\\d+\\.\\d+|\\d+)\", raw_score_text)\n",
    "        review_score = match.group(1) if match else \"N/A\"\n",
    "\n",
    "        return review_score\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"🚨 Error extracting review_score: {e}\")\n",
    "        return \"N/A\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import re\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# ✅ Helper function to extract text safely\n",
    "def extract_text(card, xpath):\n",
    "    try:\n",
    "        return card.find_element(By.XPATH, xpath).text.strip()\n",
    "    except:\n",
    "        return \"N/A\"\n",
    "\n",
    "\n",
    "def scrape_booking_reviews(driver, max_retries=3):\n",
    "    \"\"\"\n",
    "    Scrapes hotel reviews from Booking.com while handling detection issues.\n",
    "    - Clicks \"Show All Reviews\" if detected.\n",
    "    - Retries scraping up to 3 times if no reviews load.\n",
    "    - Extracts reviewer names, stay details, review scores, and comments.\n",
    "    \"\"\"\n",
    "    time.sleep(random.uniform(3, 7))  # Wait randomly to mimic human behavior\n",
    "    wait = WebDriverWait(driver, 10)  \n",
    "    all_reviews = []\n",
    "    no_comment_count = 0\n",
    "    attempts = 0\n",
    "\n",
    "    while attempts < max_retries:\n",
    "        try:\n",
    "            # Step 1: Click \"Read all reviews\" (only once per hotel)\n",
    "            click_read_all_reviews(driver)\n",
    "\n",
    "            # Step 2: Check if Booking.com is hiding reviews\n",
    "            try:\n",
    "                show_all_reviews_btn = driver.find_element(By.XPATH, \"//a[contains(text(), 'Show all reviews')]\")\n",
    "                if show_all_reviews_btn.is_displayed():\n",
    "                    print(\"🔄 Clicking 'Show All Reviews' button...\")\n",
    "                    driver.execute_script(\"arguments[0].click();\", show_all_reviews_btn)\n",
    "                    time.sleep(random.uniform(2, 4))  # Wait for reviews to load\n",
    "            except Exception:\n",
    "                pass  # Button not found = continue scraping\n",
    "\n",
    "            # Step 3: Loop through review pages\n",
    "            while True:\n",
    "                review_cards = wait.until(\n",
    "                    EC.presence_of_all_elements_located((By.XPATH, \"//div[@data-testid='review-card']\"))\n",
    "                )\n",
    "\n",
    "                for card in review_cards:\n",
    "                    try:\n",
    "                        # Extract reviewer details\n",
    "                        reviewer_name = extract_text(card, \".//div[contains(@class, 'a3332d346a e6208ee469')]\")\n",
    "                        reviewer_country = extract_text(card, \".//span[contains(@class, 'afac1f68d9')]\")\n",
    "                        review_room_name = extract_text(card, \".//span[@data-testid='review-room-name']\")\n",
    "                        review_num_nights = extract_text(card, \".//span[@data-testid='review-num-nights']\").split()[0]\n",
    "                        review_stay_date = extract_text(card, \".//span[@data-testid='review-stay-date']\")\n",
    "                        review_traveler_type = extract_text(card, \".//span[@data-testid='review-traveler-type']\")\n",
    "                        review_title = extract_text(card, \".//h3[@data-testid='review-title']\")\n",
    "                        review_score = extract_review_score(card)\n",
    "                        review_positive_text = extract_text(card, \".//div[@data-testid='review-positive-text']//div[contains(@class, 'a53cbfa6de b5726afd0b')]\")\n",
    "                        review_negative_text = extract_text(card, \".//div[@data-testid='review-negative-text']//div[contains(@class, 'a53cbfa6de b5726afd0b')]\")\n",
    "\n",
    "                        # Check for reviews with no comments\n",
    "                        if review_positive_text == \"N/A\" and review_negative_text == \"N/A\":\n",
    "                            no_comment_count += 1\n",
    "                        else:\n",
    "                            no_comment_count = 0\n",
    "\n",
    "                        if no_comment_count >= 5:\n",
    "                            print(\"⚠️ Stopping: 5 consecutive reviews without comments.\")\n",
    "                            return all_reviews\n",
    "\n",
    "                        # Store the review data\n",
    "                        all_reviews.append({\n",
    "                            \"reviewer_name\": reviewer_name,\n",
    "                            \"reviewer_country\": reviewer_country,\n",
    "                            \"review_room_name\": review_room_name,\n",
    "                            \"review_num_nights\": review_num_nights,\n",
    "                            \"review_stay_date\": review_stay_date,\n",
    "                            \"review_traveler_type\": review_traveler_type,\n",
    "                            \"review_score\": review_score,\n",
    "                            \"review_title\": review_title,\n",
    "                            \"review_positive_text\": review_positive_text,\n",
    "                            \"review_negative_text\": review_negative_text\n",
    "                        })\n",
    "\n",
    "                    except Exception:\n",
    "                        continue  # Skip if any issue occurs\n",
    "\n",
    "                # Step 4: Click 'Next page' (break loop if last page)\n",
    "                if not click_next_page(driver):\n",
    "                    break\n",
    "\n",
    "            if all_reviews:\n",
    "                print(f\"✅ Successfully extracted {len(all_reviews)} reviews.\")\n",
    "                return all_reviews  # Return if reviews were found\n",
    "\n",
    "            print(f\"⚠️ No reviews found, retrying... ({attempts+1}/{max_retries})\")\n",
    "            time.sleep(random.uniform(3, 6))  # Random wait before retrying\n",
    "            driver.refresh()  # Reload page to try again\n",
    "            attempts += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"🚨 Error while scraping reviews: {e}\")\n",
    "            time.sleep(random.uniform(3, 6))\n",
    "            driver.refresh()\n",
    "            attempts += 1\n",
    "\n",
    "    print(\"❌ Maximum retries reached. No reviews extracted.\")\n",
    "    return all_reviews\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 1] Skipped (already completed).\n",
      "[Batch 2] Skipped (already completed).\n",
      "[Batch 3] Skipped (already completed).\n",
      "[Batch 4] Skipped (already completed).\n",
      "[Batch 5] Skipped (already completed).\n",
      "[Batch 6] Skipped (already completed).\n",
      "[Batch 7] Skipped (already completed).\n",
      "[Batch 8] Skipped (already completed).\n",
      "[Batch 9] Skipped (already completed).\n",
      "[Batch 10] Skipped (already completed).\n",
      "[Batch 11] Skipped (already completed).\n",
      "[Batch 12] Skipped (already completed).\n",
      "[Batch 13] Skipped (already completed).\n",
      "[Batch 14] Skipped (already completed).\n",
      "[Batch 15] Skipped (already completed).\n",
      "[Batch 16] Skipped (already completed).\n",
      "[Batch 17] Skipped (already completed).\n",
      "[Batch 18] Skipped (already completed).\n",
      "[Batch 19] Skipped (already completed).\n",
      "[Batch 20] Skipped (already completed).\n",
      "[Batch 21] Skipped (already completed).\n",
      "[Batch 22] Skipped (already completed).\n",
      "[Batch 23] Skipped (already completed).\n",
      "[Batch 24] Skipped (already completed).\n",
      "[Batch 25] Skipped (already completed).\n",
      "[Batch 26] Skipped (already completed).\n",
      "[Batch 27] Skipped (already completed).\n",
      "[Batch 28] Skipped (already completed).\n",
      "[Batch 29] Skipped (already completed).\n",
      "[Batch 30] Skipped (already completed).\n",
      "[Batch 31] Skipped (already completed).\n",
      "[Batch 32] Skipped (already completed).\n",
      "[Batch 33] Skipped (already completed).\n",
      "[Batch 34] Skipped (already completed).\n",
      "[Batch 35] Skipped (already completed).\n",
      "[Batch 36] Skipped (already completed).\n",
      "[Batch 37] Skipped (already completed).\n",
      "[Batch 38] Skipped (already completed).\n",
      "[Batch 39] Skipped (already completed).\n",
      "[Batch 40] Skipped (already completed).\n",
      "[Batch 41] Skipped (already completed).\n",
      "[Batch 42] Skipped (already completed).\n",
      "[Batch 43] Skipped (already completed).\n",
      "[Batch 44] Skipped (already completed).\n",
      "[Batch 45] Skipped (already completed).\n",
      "[Batch 46] Skipped (already completed).\n",
      "[Batch 47] Skipped (already completed).\n",
      "[Batch 48] Skipped (already completed).\n",
      "[Batch 49] Skipped (already completed).\n",
      "[Batch 50] Skipped (already completed).\n",
      "[Batch 51] Skipped (already completed).\n",
      "[Batch 52] Skipped (already completed).\n",
      "[Batch 53] Skipped (already completed).\n",
      "[Batch 54] Skipped (already completed).\n",
      "[Batch 55] Skipped (already completed).\n",
      "[Batch 56] Skipped (already completed).\n",
      "[Batch 57] Skipped (already completed).\n",
      "[Batch 58] Skipped (already completed).\n",
      "[Batch 59] Skipped (already completed).\n",
      "[Batch 60] Skipped (already completed).\n",
      "[Batch 61] Skipped (already completed).\n",
      "[Batch 62] Skipped (already completed).\n",
      "[Batch 63] Skipped (already completed).\n",
      "[Batch 64] Skipped (already completed).\n",
      "[Batch 65] Skipped (already completed).\n",
      "[Batch 66] Skipped (already completed).\n",
      "[Batch 67] Skipped (already completed).\n",
      "[Batch 68] Skipped (already completed).\n",
      "[Batch 69] Skipped (already completed).\n",
      "[Batch 70] Skipped (already completed).\n",
      "[Batch 71] Skipped (already completed).\n",
      "[Batch 72] Skipped (already completed).\n",
      "[Batch 73] Skipped (already completed).\n",
      "[Batch 74] Skipped (already completed).\n",
      "[Batch 75] Skipped (already completed).\n",
      "[Batch 76] Skipped (already completed).\n",
      "[Batch 77] Skipped (already completed).\n",
      "[Batch 78] Skipped (already completed).\n",
      "[Batch 79] Skipped (already completed).\n",
      "[Batch 80] Skipped (already completed).\n",
      "[Batch 81] Skipped (already completed).\n",
      "[Batch 82] Skipped (already completed).\n",
      "[Batch 83] Skipped (already completed).\n",
      "[Batch 84] Skipped (already completed).\n",
      "[Batch 85] Skipped (already completed).\n",
      "[Batch 86] Skipped (already completed).\n",
      "[Batch 87] Skipped (already completed).\n",
      "[Batch 88] Skipped (already completed).\n",
      "[Batch 89] Skipped (already completed).\n",
      "[Batch 90] Skipped (already completed).\n",
      "[Batch 91] Skipped (already completed).\n",
      "[Batch 92] Skipped (already completed).\n",
      "[Batch 93] Skipped (already completed).\n",
      "[Batch 94] Skipped (already completed).\n",
      "[Batch 95] Skipped (already completed).\n",
      "[Batch 96] Skipped (already completed).\n",
      "[Batch 97] Skipped (already completed).\n",
      "[Batch 98] Skipped (already completed).\n",
      "[Batch 99] Skipped (already completed).\n",
      "[Batch 100] Skipped (already completed).\n",
      "[Batch 101] Skipped (already completed).\n",
      "[Batch 102] Skipped (already completed).\n",
      "[Batch 103] Skipped (already completed).\n",
      "[Batch 104] Skipped (already completed).\n",
      "[Batch 105] Skipped (already completed).\n",
      "[Batch 106] Skipped (already completed).\n",
      "[Batch 107] Skipped (already completed).\n",
      "[Batch 108] Skipped (already completed).\n",
      "[Batch 109] Skipped (already completed).\n",
      "[Batch 110] Skipped (already completed).\n",
      "[Batch 111] Skipped (already completed).\n",
      "[Batch 112] Skipped (already completed).\n",
      "[Batch 113] Skipped (already completed).\n",
      "[Batch 114] Skipped (already completed).\n",
      "[Batch 115] Skipped (already completed).\n",
      "[Batch 116] Skipped (already completed).\n",
      "[Batch 117] Skipped (already completed).\n",
      "[Batch 118] Skipped (already completed).\n",
      "[Batch 119] Skipped (already completed).\n",
      "[Batch 120] Skipped (already completed).\n",
      "[Batch 121] Skipped (already completed).\n",
      "[Batch 122] Skipped (already completed).\n",
      "[Batch 123] Skipped (already completed).\n",
      "[Batch 124] Skipped (already completed).\n",
      "[Batch 125] Skipped (already completed).\n",
      "[Batch 126] Skipped (already completed).\n",
      "[Batch 127] Skipped (already completed).\n",
      "[Batch 128] Skipped (already completed).\n",
      "[Batch 129] Skipped (already completed).\n",
      "[Batch 130] Skipped (already completed).\n",
      "[Batch 131] Skipped (already completed).\n",
      "[Batch 132] Skipped (already completed).\n",
      "[Batch 133] Skipped (already completed).\n",
      "[Batch 134] Skipped (already completed).\n",
      "[Batch 135] Skipped (already completed).\n",
      "[Batch 136] Skipped (already completed).\n",
      "[Batch 137] Skipped (already completed).\n",
      "[Batch 138] Skipped (already completed).\n",
      "[Batch 139] Skipped (already completed).\n",
      "[Batch 140] Skipped (already completed).\n",
      "[Batch 141] Skipped (already completed).\n",
      "[Batch 142] Skipped (already completed).\n",
      "[Batch 143] Skipped (already completed).\n",
      "[Batch 144] Skipped (already completed).\n",
      "[Batch 145] Skipped (already completed).\n",
      "[Batch 146] Skipped (already completed).\n",
      "[Batch 147] Skipped (already completed).\n",
      "[Batch 148] Skipped (already completed).\n",
      "[Batch 149] Skipped (already completed).\n",
      "[Batch 150] Skipped (already completed).\n",
      "[Batch 151] Skipped (already completed).\n",
      "[Batch 152] Skipped (already completed).\n",
      "[Batch 153] Skipped (already completed).\n",
      "[Batch 154] Skipped (already completed).\n",
      "[Batch 155] Skipped (already completed).\n",
      "[Batch 156] Skipped (already completed).\n",
      "[Batch 157] Skipped (already completed).\n",
      "[Batch 158] Skipped (already completed).\n",
      "[Batch 159] Skipped (already completed).\n",
      "[Batch 160] Skipped (already completed).\n",
      "[Batch 161] Skipped (already completed).\n",
      "[Batch 162] Skipped (already completed).\n",
      "[Batch 163] Skipped (already completed).\n",
      "[Batch 164] Skipped (already completed).\n",
      "[Batch 165] Skipped (already completed).\n",
      "[Batch 166] Skipped (already completed).\n",
      "[Batch 167] Skipped (already completed).\n",
      "[Batch 168] Skipped (already completed).\n",
      "[Batch 169] Skipped (already completed).\n",
      "[Batch 170] Skipped (already completed).\n",
      "[Batch 171] Skipped (already completed).\n",
      "[Batch 172] Skipped (already completed).\n",
      "[Batch 173] Skipped (already completed).\n",
      "[Batch 174] Skipped (already completed).\n",
      "[Batch 175] Skipped (already completed).\n",
      "[Batch 176] Skipped (already completed).\n",
      "[Batch 177] Skipped (already completed).\n",
      "[Batch 178] Skipped (already completed).\n",
      "[Batch 179] Skipped (already completed).\n",
      "[Batch 180] Skipped (already completed).\n",
      "[Batch 181] Skipped (already completed).\n",
      "[Batch 182] Skipped (already completed).\n",
      "[Batch 183] Skipped (already completed).\n",
      "[Batch 184] Skipped (already completed).\n",
      "[Batch 185] Skipped (already completed).\n",
      "[Batch 186] Skipped (already completed).\n",
      "[Batch 187] Skipped (already completed).\n",
      "[Batch 188] Skipped (already completed).\n",
      "[Batch 189] Skipped (already completed).\n",
      "[Batch 190] Skipped (already completed).\n",
      "[Batch 191] Skipped (already completed).\n",
      "[Batch 192] Skipped (already completed).\n",
      "[Batch 193] Skipped (already completed).\n",
      "[Batch 194] Skipped (already completed).\n",
      "[Batch 195] Skipped (already completed).\n",
      "[Batch 196] Skipped (already completed).\n",
      "[Batch 197] Skipped (already completed).\n",
      "[Batch 198] Skipped (already completed).\n",
      "[Batch 199] Skipped (already completed).\n",
      "[Batch 200] Skipped (already completed).\n",
      "[Batch 201] Skipped (already completed).\n",
      "[Batch 202] Skipped (already completed).\n",
      "[Batch 203] Skipped (already completed).\n",
      "[Batch 204] Skipped (already completed).\n",
      "[Batch 205] Skipped (already completed).\n",
      "[Batch 206] Skipped (already completed).\n",
      "[Batch 207] Skipped (already completed).\n",
      "[Batch 208] Skipped (already completed).\n",
      "[Batch 209] Skipped (already completed).\n",
      "[Batch 210] Skipped (already completed).\n",
      "[Batch 211] Skipped (already completed).\n",
      "[Batch 212] Skipped (already completed).\n",
      "[Batch 213] Skipped (already completed).\n",
      "[Batch 214] Skipped (already completed).\n",
      "[Batch 215] Skipped (already completed).\n",
      "[Batch 216] Skipped (already completed).\n",
      "[Batch 217] Skipped (already completed).\n",
      "[Batch 218] Skipped (already completed).\n",
      "[Batch 219] Skipped (already completed).\n",
      "[Batch 220] Skipped (already completed).\n",
      "[Batch 221] Skipped (already completed).\n",
      "[Batch 222] Skipped (already completed).\n",
      "[Batch 223] Skipped (already completed).\n",
      "[Batch 224] Skipped (already completed).\n",
      "[Batch 225] Skipped (already completed).\n",
      "[Batch 226] Skipped (already completed).\n",
      "[Batch 227] Skipped (already completed).\n",
      "[Batch 228] Skipped (already completed).\n",
      "[Batch 229] Skipped (already completed).\n",
      "[Batch 230] Skipped (already completed).\n",
      "[Batch 231] Skipped (already completed).\n",
      "[Batch 232] Skipped (already completed).\n",
      "[Batch 233] Skipped (already completed).\n",
      "[Batch 234] Skipped (already completed).\n",
      "[Batch 235] Skipped (already completed).\n",
      "[Batch 236] Skipped (already completed).\n",
      "[Batch 237] Skipped (already completed).\n",
      "[Batch 238] Skipped (already completed).\n",
      "[Batch 239] Skipped (already completed).\n",
      "[Batch 240] Skipped (already completed).\n",
      "[Batch 241] Skipped (already completed).\n",
      "[Batch 242] Skipped (already completed).\n",
      "[Batch 243] Skipped (already completed).\n",
      "[Batch 244] Skipped (already completed).\n",
      "[Batch 245] Skipped (already completed).\n",
      "[Batch 246] Skipped (already completed).\n",
      "[Batch 247] Skipped (already completed).\n",
      "[Batch 248] Skipped (already completed).\n",
      "[Batch 249] Skipped (already completed).\n",
      "[Batch 250] Skipped (already completed).\n",
      "[Batch 251] Skipped (already completed).\n",
      "[Batch 252] Skipped (already completed).\n",
      "[Batch 253] Skipped (already completed).\n",
      "[Batch 254] Skipped (already completed).\n",
      "[Batch 255] Skipped (already completed).\n",
      "[Batch 256] Skipped (already completed).\n",
      "[Batch 257] Skipped (already completed).\n",
      "[Batch 258] Skipped (already completed).\n",
      "[Batch 259] Skipped (already completed).\n",
      "[Batch 260] Skipped (already completed).\n",
      "[Batch 261] Skipped (already completed).\n",
      "[Batch 262] Skipped (already completed).\n",
      "[Batch 263] Skipped (already completed).\n",
      "[Batch 264] Skipped (already completed).\n",
      "[Batch 265] Skipped (already completed).\n",
      "[Batch 266] Skipped (already completed).\n",
      "[Batch 267] Skipped (already completed).\n",
      "[Batch 268] Skipped (already completed).\n",
      "[Batch 269] Skipped (already completed).\n",
      "[Batch 270] Skipped (already completed).\n",
      "[Batch 271] Skipped (already completed).\n",
      "[Batch 272] Skipped (already completed).\n",
      "[Batch 273] Skipped (already completed).\n",
      "[Batch 274] Skipped (already completed).\n",
      "[Batch 275] Skipped (already completed).\n",
      "[Batch 276] Skipped (already completed).\n",
      "[Batch 277] Skipped (already completed).\n",
      "[Batch 278] Skipped (already completed).\n",
      "[Batch 279] Skipped (already completed).\n",
      "[Batch 280] Skipped (already completed).\n",
      "[Batch 281] Skipped (already completed).\n",
      "[Batch 282] Skipped (already completed).\n",
      "[Batch 283] Skipped (already completed).\n",
      "[Batch 284] Skipped (already completed).\n",
      "[Batch 285] Skipped (already completed).\n",
      "[Batch 286] Skipped (already completed).\n",
      "[Batch 287] Skipped (already completed).\n",
      "[Batch 288] Skipped (already completed).\n",
      "[Batch 289] Skipped (already completed).\n",
      "[Batch 290] Skipped (already completed).\n",
      "[Batch 291] Skipped (already completed).\n",
      "[Batch 292] Skipped (already completed).\n",
      "[Batch 293] Skipped (already completed).\n",
      "[Batch 294] Skipped (already completed).\n",
      "[Batch 295] Skipped (already completed).\n",
      "[Batch 296] Skipped (already completed).\n",
      "[Batch 297] Skipped (already completed).\n",
      "[Batch 298] Skipped (already completed).\n",
      "[Batch 299] Skipped (already completed).\n",
      "[Batch 300] Skipped (already completed).\n",
      "[Batch 301] Skipped (already completed).\n",
      "[Batch 302] Skipped (already completed).\n",
      "[Batch 303] Skipped (already completed).\n",
      "[Batch 304] Skipped (already completed).\n",
      "[Batch 305] Skipped (already completed).\n",
      "[Batch 306] Skipped (already completed).\n",
      "[Batch 307] Skipped (already completed).\n",
      "[Batch 308] Skipped (already completed).\n",
      "[Batch 309] Skipped (already completed).\n",
      "[Batch 310] Skipped (already completed).\n",
      "[Batch 311] Skipped (already completed).\n",
      "[Batch 312] Skipped (already completed).\n",
      "[Batch 313] Skipped (already completed).\n",
      "[Batch 314] Skipped (already completed).\n",
      "[Batch 315] Skipped (already completed).\n",
      "[Batch 316] Skipped (already completed).\n",
      "[Batch 317] Skipped (already completed).\n",
      "[Batch 318] Skipped (already completed).\n",
      "[Batch 319] Skipped (already completed).\n",
      "[Batch 320] Skipped (already completed).\n",
      "[Batch 321] Skipped (already completed).\n",
      "[Batch 322] Skipped (already completed).\n",
      "[Batch 323] Skipped (already completed).\n",
      "[Batch 324] Skipped (already completed).\n",
      "[Batch 325] Skipped (already completed).\n",
      "[Batch 326] Skipped (already completed).\n",
      "[Batch 327] Skipped (already completed).\n",
      "[Batch 328] Skipped (already completed).\n",
      "[Batch 329] Skipped (already completed).\n",
      "[Batch 330] Skipped (already completed).\n",
      "[Batch 331] Skipped (already completed).\n",
      "[Batch 332] Skipped (already completed).\n",
      "[Batch 333] Skipped (already completed).\n",
      "[Batch 334] Skipped (already completed).\n",
      "[Batch 335] Skipped (already completed).\n",
      "[Batch 336] Skipped (already completed).\n",
      "[Batch 337] Skipped (already completed).\n",
      "[Batch 338] Skipped (already completed).\n",
      "[Batch 339] Skipped (already completed).\n",
      "[Batch 340] Skipped (already completed).\n",
      "[Batch 341] Skipped (already completed).\n",
      "[Batch 342] Skipped (already completed).\n",
      "[Batch 343] Skipped (already completed).\n",
      "[Batch 344] Skipped (already completed).\n",
      "[Batch 345] Skipped (already completed).\n",
      "[Batch 346] Skipped (already completed).\n",
      "[Batch 347] Skipped (already completed).\n",
      "[Batch 348] Skipped (already completed).\n",
      "[Batch 349] Skipped (already completed).\n",
      "[Batch 350] Skipped (already completed).\n",
      "[Batch 351] Skipped (already completed).\n",
      "[Batch 352] Skipped (already completed).\n",
      "[Batch 353] Skipped (already completed).\n",
      "[Batch 354] Skipped (already completed).\n",
      "[Batch 355] Skipped (already completed).\n",
      "[Batch 356] Skipped (already completed).\n",
      "[Batch 357] Skipped (already completed).\n",
      "[Batch 358] Skipped (already completed).\n",
      "[Batch 359] Skipped (already completed).\n",
      "[Batch 360] Skipped (already completed).\n",
      "[Batch 361] Skipped (already completed).\n",
      "[Batch 362] Skipped (already completed).\n",
      "[Batch 363] Starting scrape...\n",
      "[Batch 364] Skipped (already completed).\n",
      "[Batch 365] Skipped (already completed).\n",
      "[Batch 366] Skipped (already completed).\n",
      "[Batch 367] Skipped (already completed).\n",
      "[Batch 368] Skipped (already completed).\n",
      "[Batch 369] Skipped (already completed).\n",
      "[Batch 370] Skipped (already completed).\n",
      "[Batch 371] Skipped (already completed).\n",
      "[Batch 372] Skipped (already completed).\n",
      "[Batch 373] Skipped (already completed).\n",
      "[Batch 374] Starting scrape...\n",
      "[Batch 375] Skipped (already completed).\n",
      "[Batch 376] Starting scrape...\n",
      "[Batch 377] Skipped (already completed).\n",
      "[Batch 378] Starting scrape...\n",
      "[Batch 379] Skipped (already completed).\n",
      "[Batch 380] Skipped (already completed).\n",
      "[Batch 381] Starting scrape...\n",
      "[Batch 382] Starting scrape...\n",
      "[Batch 383] Starting scrape...\n",
      "[Batch 384] Skipped (already completed).\n",
      "[Batch 385] Skipped (already completed).\n",
      "[Batch 386] Skipped (already completed).\n",
      "[Batch 387] Starting scrape...\n",
      "[Batch 388] Skipped (already completed).\n",
      "[Batch 389] Skipped (already completed).\n",
      "[Batch 390] Skipped (already completed).\n",
      "[Batch 391] Skipped (already completed).\n",
      "[Batch 392] Skipped (already completed).\n",
      "[Batch 393] Skipped (already completed).\n",
      "[Batch 394] Skipped (already completed).\n",
      "[Batch 395] Skipped (already completed).\n",
      "[Batch 396] Skipped (already completed).\n",
      "[Batch 397] Skipped (already completed).\n",
      "[Batch 398] Skipped (already completed).\n",
      "[Batch 399] Skipped (already completed).\n",
      "[Batch 400] Skipped (already completed).\n",
      "[Batch 401] Skipped (already completed).\n",
      "[Batch 402] Skipped (already completed).\n",
      "[Batch 403] Skipped (already completed).\n",
      "[Batch 404] Skipped (already completed).\n",
      "[Batch 405] Skipped (already completed).\n",
      "[Batch 406] Skipped (already completed).\n",
      "[Batch 407] Skipped (already completed).\n",
      "[Batch 408] Skipped (already completed).\n",
      "[Batch 409] Skipped (already completed).\n",
      "[Batch 410] Skipped (already completed).\n",
      "[Batch 411] Skipped (already completed).\n",
      "[Batch 412] Skipped (already completed).\n",
      "[Batch 413] Skipped (already completed).\n",
      "[Batch 414] Skipped (already completed).\n",
      "[Batch 415] Starting scrape...\n",
      "[Batch 416] Skipped (already completed).\n",
      "[Batch 417] Skipped (already completed).\n",
      "[Batch 418] Skipped (already completed).\n",
      "[Batch 419] Skipped (already completed).\n",
      "[Batch 420] Skipped (already completed).\n",
      "[Batch 421] Skipped (already completed).\n",
      "[Batch 422] Skipped (already completed).\n",
      "[Batch 423] Skipped (already completed).\n",
      "[Batch 424] Skipped (already completed).\n",
      "[Batch 425] Skipped (already completed).\n",
      "[Batch 426] Skipped (already completed).\n",
      "[Batch 427] Skipped (already completed).\n",
      "[Batch 428] Skipped (already completed).\n",
      "[Batch 429] Skipped (already completed).\n",
      "[Batch 430] Skipped (already completed).\n",
      "[Batch 431] Skipped (already completed).\n",
      "[Batch 432] Starting scrape...\n",
      "[Batch 433] Skipped (already completed).\n",
      "[Batch 434] Skipped (already completed).\n",
      "[Batch 435] Skipped (already completed).\n",
      "[Batch 436] Skipped (already completed).\n",
      "[Batch 437] Skipped (already completed).\n",
      "[Batch 438] Skipped (already completed).\n",
      "[Batch 439] Skipped (already completed).\n",
      "[Batch 440] Skipped (already completed).\n",
      "[Batch 441] Skipped (already completed).\n",
      "[Batch 442] Skipped (already completed).\n",
      "[Batch 443] Skipped (already completed).\n",
      "[Batch 444] Skipped (already completed).\n",
      "[Batch 445] Starting scrape...\n",
      "[Batch 446] Starting scrape...\n",
      "[Batch 447] Starting scrape...\n",
      "[Batch 448] Starting scrape...\n",
      "[Batch 449] Starting scrape...\n",
      "[Batch 381] Scraping: Ultra Luxury Family House\n",
      "[Batch 432] Scraping: The Quay Hotel Little India\n",
      "[Batch 383] Scraping: Bart house\n",
      "[Batch 445] Scraping: Marina Bay Sands\n",
      "[Batch 363] Scraping: Social-Inn Norris Road Apt\n",
      "[Batch 387] Scraping: MASTER BEDROOM SUITE\n",
      "[Batch 382] Scraping: Raffles Sentosa Singapore\n",
      "[Batch 446] Scraping: Marina Bay Sands\n",
      "[Batch 448] Scraping: Marina Bay Sands\n",
      "[Batch 374] Scraping: A Desker Hotel, Stay From 6PM to 9AM\n",
      "[Batch 415] Scraping: Mandai Rainforest Resort by Banyan Tree\n",
      "[Batch 376] Scraping: Downtown Apartment\n",
      "[Batch 449] Scraping: Marina Bay Sands\n",
      "[Batch 378] Scraping: 36 club st residence\n",
      "[Batch 447] Scraping: Marina Bay Sands\n",
      "Failed to click 'Read all reviews' button: Message: stale element reference: stale element not found in the current frame\n",
      "  (Session info: chrome=134.0.6998.118); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#stale-element-reference-exception\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF6D6C54C25+3179557]\n",
      "\t(No symbol) [0x00007FF6D68B88A0]\n",
      "\t(No symbol) [0x00007FF6D67491CA]\n",
      "\t(No symbol) [0x00007FF6D6750B98]\n",
      "\t(No symbol) [0x00007FF6D6753BCC]\n",
      "\t(No symbol) [0x00007FF6D6753C9F]\n",
      "\t(No symbol) [0x00007FF6D67A1BAD]\n",
      "\t(No symbol) [0x00007FF6D6792990]\n",
      "\t(No symbol) [0x00007FF6D67C7C2A]\n",
      "\t(No symbol) [0x00007FF6D67922D6]\n",
      "\t(No symbol) [0x00007FF6D67C7E40]\n",
      "\t(No symbol) [0x00007FF6D67F02F3]\n",
      "\t(No symbol) [0x00007FF6D67C7A03]\n",
      "\t(No symbol) [0x00007FF6D67906D0]\n",
      "\t(No symbol) [0x00007FF6D6791983]\n",
      "\tGetHandleVerifier [0x00007FF6D6CB67CD+3579853]\n",
      "\tGetHandleVerifier [0x00007FF6D6CCD1D2+3672530]\n",
      "\tGetHandleVerifier [0x00007FF6D6CC2153+3627347]\n",
      "\tGetHandleVerifier [0x00007FF6D6A2092A+868650]\n",
      "\t(No symbol) [0x00007FF6D68C2FFF]\n",
      "\t(No symbol) [0x00007FF6D68BF4A4]\n",
      "\t(No symbol) [0x00007FF6D68BF646]\n",
      "\t(No symbol) [0x00007FF6D68AEAA9]\n",
      "\tBaseThreadInitThunk [0x00007FF93949E8D7+23]\n",
      "\tRtlUserThreadStart [0x00007FF93A3BBF6C+44]\n",
      "\n",
      "Failed to click 'Read all reviews' button: Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF6D6C54C25+3179557]\n",
      "\t(No symbol) [0x00007FF6D68B88A0]\n",
      "\t(No symbol) [0x00007FF6D67491CA]\n",
      "\t(No symbol) [0x00007FF6D679FA67]\n",
      "\t(No symbol) [0x00007FF6D679FC9C]\n",
      "\t(No symbol) [0x00007FF6D67F3627]\n",
      "\t(No symbol) [0x00007FF6D67C7C6F]\n",
      "\t(No symbol) [0x00007FF6D67F02F3]\n",
      "\t(No symbol) [0x00007FF6D67C7A03]\n",
      "\t(No symbol) [0x00007FF6D67906D0]\n",
      "\t(No symbol) [0x00007FF6D6791983]\n",
      "\tGetHandleVerifier [0x00007FF6D6CB67CD+3579853]\n",
      "\tGetHandleVerifier [0x00007FF6D6CCD1D2+3672530]\n",
      "\tGetHandleVerifier [0x00007FF6D6CC2153+3627347]\n",
      "\tGetHandleVerifier [0x00007FF6D6A2092A+868650]\n",
      "\t(No symbol) [0x00007FF6D68C2FFF]\n",
      "\t(No symbol) [0x00007FF6D68BF4A4]\n",
      "\t(No symbol) [0x00007FF6D68BF646]\n",
      "\t(No symbol) [0x00007FF6D68AEAA9]\n",
      "\tBaseThreadInitThunk [0x00007FF93949E8D7+23]\n",
      "\tRtlUserThreadStart [0x00007FF93A3BBF6C+44]\n",
      "\n",
      "Failed to click 'Read all reviews' button: Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF6D6C54C25+3179557]\n",
      "\t(No symbol) [0x00007FF6D68B88A0]\n",
      "\t(No symbol) [0x00007FF6D67491CA]\n",
      "\t(No symbol) [0x00007FF6D679FA67]\n",
      "\t(No symbol) [0x00007FF6D679FC9C]\n",
      "\t(No symbol) [0x00007FF6D67F3627]\n",
      "\t(No symbol) [0x00007FF6D67C7C6F]\n",
      "\t(No symbol) [0x00007FF6D67F02F3]\n",
      "\t(No symbol) [0x00007FF6D67C7A03]\n",
      "\t(No symbol) [0x00007FF6D67906D0]\n",
      "\t(No symbol) [0x00007FF6D6791983]\n",
      "\tGetHandleVerifier [0x00007FF6D6CB67CD+3579853]\n",
      "\tGetHandleVerifier [0x00007FF6D6CCD1D2+3672530]\n",
      "\tGetHandleVerifier [0x00007FF6D6CC2153+3627347]\n",
      "\tGetHandleVerifier [0x00007FF6D6A2092A+868650]\n",
      "\t(No symbol) [0x00007FF6D68C2FFF]\n",
      "\t(No symbol) [0x00007FF6D68BF4A4]\n",
      "\t(No symbol) [0x00007FF6D68BF646]\n",
      "\t(No symbol) [0x00007FF6D68AEAA9]\n",
      "\tBaseThreadInitThunk [0x00007FF93949E8D7+23]\n",
      "\tRtlUserThreadStart [0x00007FF93A3BBF6C+44]\n",
      "\n",
      "Failed to click 'Read all reviews' button: Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF6D6C54C25+3179557]\n",
      "\t(No symbol) [0x00007FF6D68B88A0]\n",
      "\t(No symbol) [0x00007FF6D67491CA]\n",
      "\t(No symbol) [0x00007FF6D679FA67]\n",
      "\t(No symbol) [0x00007FF6D679FC9C]\n",
      "\t(No symbol) [0x00007FF6D67F3627]\n",
      "\t(No symbol) [0x00007FF6D67C7C6F]\n",
      "\t(No symbol) [0x00007FF6D67F02F3]\n",
      "\t(No symbol) [0x00007FF6D67C7A03]\n",
      "\t(No symbol) [0x00007FF6D67906D0]\n",
      "\t(No symbol) [0x00007FF6D6791983]\n",
      "\tGetHandleVerifier [0x00007FF6D6CB67CD+3579853]\n",
      "\tGetHandleVerifier [0x00007FF6D6CCD1D2+3672530]\n",
      "\tGetHandleVerifier [0x00007FF6D6CC2153+3627347]\n",
      "\tGetHandleVerifier [0x00007FF6D6A2092A+868650]\n",
      "\t(No symbol) [0x00007FF6D68C2FFF]\n",
      "\t(No symbol) [0x00007FF6D68BF4A4]\n",
      "\t(No symbol) [0x00007FF6D68BF646]\n",
      "\t(No symbol) [0x00007FF6D68AEAA9]\n",
      "\tBaseThreadInitThunk [0x00007FF93949E8D7+23]\n",
      "\tRtlUserThreadStart [0x00007FF93A3BBF6C+44]\n",
      "\n",
      "Failed to click 'Read all reviews' button: Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF6D6C54C25+3179557]\n",
      "\t(No symbol) [0x00007FF6D68B88A0]\n",
      "\t(No symbol) [0x00007FF6D67491CA]\n",
      "\t(No symbol) [0x00007FF6D679FA67]\n",
      "\t(No symbol) [0x00007FF6D679FC9C]\n",
      "\t(No symbol) [0x00007FF6D67F3627]\n",
      "\t(No symbol) [0x00007FF6D67C7C6F]\n",
      "\t(No symbol) [0x00007FF6D67F02F3]\n",
      "\t(No symbol) [0x00007FF6D67C7A03]\n",
      "\t(No symbol) [0x00007FF6D67906D0]\n",
      "\t(No symbol) [0x00007FF6D6791983]\n",
      "\tGetHandleVerifier [0x00007FF6D6CB67CD+3579853]\n",
      "\tGetHandleVerifier [0x00007FF6D6CCD1D2+3672530]\n",
      "\tGetHandleVerifier [0x00007FF6D6CC2153+3627347]\n",
      "\tGetHandleVerifier [0x00007FF6D6A2092A+868650]\n",
      "\t(No symbol) [0x00007FF6D68C2FFF]\n",
      "\t(No symbol) [0x00007FF6D68BF4A4]\n",
      "\t(No symbol) [0x00007FF6D68BF646]\n",
      "\t(No symbol) [0x00007FF6D68AEAA9]\n",
      "\tBaseThreadInitThunk [0x00007FF93949E8D7+23]\n",
      "\tRtlUserThreadStart [0x00007FF93A3BBF6C+44]\n",
      "\n",
      "Failed to click 'Read all reviews' button: Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF6D6C54C25+3179557]\n",
      "\t(No symbol) [0x00007FF6D68B88A0]\n",
      "\t(No symbol) [0x00007FF6D67491CA]\n",
      "\t(No symbol) [0x00007FF6D679FA67]\n",
      "\t(No symbol) [0x00007FF6D679FC9C]\n",
      "\t(No symbol) [0x00007FF6D67F3627]\n",
      "\t(No symbol) [0x00007FF6D67C7C6F]\n",
      "\t(No symbol) [0x00007FF6D67F02F3]\n",
      "\t(No symbol) [0x00007FF6D67C7A03]\n",
      "\t(No symbol) [0x00007FF6D67906D0]\n",
      "\t(No symbol) [0x00007FF6D6791983]\n",
      "\tGetHandleVerifier [0x00007FF6D6CB67CD+3579853]\n",
      "\tGetHandleVerifier [0x00007FF6D6CCD1D2+3672530]\n",
      "\tGetHandleVerifier [0x00007FF6D6CC2153+3627347]\n",
      "\tGetHandleVerifier [0x00007FF6D6A2092A+868650]\n",
      "\t(No symbol) [0x00007FF6D68C2FFF]\n",
      "\t(No symbol) [0x00007FF6D68BF4A4]\n",
      "\t(No symbol) [0x00007FF6D68BF646]\n",
      "\t(No symbol) [0x00007FF6D68AEAA9]\n",
      "\tBaseThreadInitThunk [0x00007FF93949E8D7+23]\n",
      "\tRtlUserThreadStart [0x00007FF93A3BBF6C+44]\n",
      "\n",
      "Failed to click 'Read all reviews' button: Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF6D6C54C25+3179557]\n",
      "\t(No symbol) [0x00007FF6D68B88A0]\n",
      "\t(No symbol) [0x00007FF6D67491CA]\n",
      "\t(No symbol) [0x00007FF6D679FA67]\n",
      "\t(No symbol) [0x00007FF6D679FC9C]\n",
      "\t(No symbol) [0x00007FF6D67F3627]\n",
      "\t(No symbol) [0x00007FF6D67C7C6F]\n",
      "\t(No symbol) [0x00007FF6D67F02F3]\n",
      "\t(No symbol) [0x00007FF6D67C7A03]\n",
      "\t(No symbol) [0x00007FF6D67906D0]\n",
      "\t(No symbol) [0x00007FF6D6791983]\n",
      "\tGetHandleVerifier [0x00007FF6D6CB67CD+3579853]\n",
      "\tGetHandleVerifier [0x00007FF6D6CCD1D2+3672530]\n",
      "\tGetHandleVerifier [0x00007FF6D6CC2153+3627347]\n",
      "\tGetHandleVerifier [0x00007FF6D6A2092A+868650]\n",
      "\t(No symbol) [0x00007FF6D68C2FFF]\n",
      "\t(No symbol) [0x00007FF6D68BF4A4]\n",
      "\t(No symbol) [0x00007FF6D68BF646]\n",
      "\t(No symbol) [0x00007FF6D68AEAA9]\n",
      "\tBaseThreadInitThunk [0x00007FF93949E8D7+23]\n",
      "\tRtlUserThreadStart [0x00007FF93A3BBF6C+44]\n",
      "\n",
      "Failed to click 'Read all reviews' button: Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF6D6C54C25+3179557]\n",
      "\t(No symbol) [0x00007FF6D68B88A0]\n",
      "\t(No symbol) [0x00007FF6D67491CA]\n",
      "\t(No symbol) [0x00007FF6D679FA67]\n",
      "\t(No symbol) [0x00007FF6D679FC9C]\n",
      "\t(No symbol) [0x00007FF6D67F3627]\n",
      "\t(No symbol) [0x00007FF6D67C7C6F]\n",
      "\t(No symbol) [0x00007FF6D67F02F3]\n",
      "\t(No symbol) [0x00007FF6D67C7A03]\n",
      "\t(No symbol) [0x00007FF6D67906D0]\n",
      "\t(No symbol) [0x00007FF6D6791983]\n",
      "\tGetHandleVerifier [0x00007FF6D6CB67CD+3579853]\n",
      "\tGetHandleVerifier [0x00007FF6D6CCD1D2+3672530]\n",
      "\tGetHandleVerifier [0x00007FF6D6CC2153+3627347]\n",
      "\tGetHandleVerifier [0x00007FF6D6A2092A+868650]\n",
      "\t(No symbol) [0x00007FF6D68C2FFF]\n",
      "\t(No symbol) [0x00007FF6D68BF4A4]\n",
      "\t(No symbol) [0x00007FF6D68BF646]\n",
      "\t(No symbol) [0x00007FF6D68AEAA9]\n",
      "\tBaseThreadInitThunk [0x00007FF93949E8D7+23]\n",
      "\tRtlUserThreadStart [0x00007FF93A3BBF6C+44]\n",
      "\n",
      "Failed to click 'Read all reviews' button: Message: stale element reference: stale element not found in the current frame\n",
      "  (Session info: chrome=134.0.6998.118); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#stale-element-reference-exception\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF6D6C54C25+3179557]\n",
      "\t(No symbol) [0x00007FF6D68B88A0]\n",
      "\t(No symbol) [0x00007FF6D67491CA]\n",
      "\t(No symbol) [0x00007FF6D6750B98]\n",
      "\t(No symbol) [0x00007FF6D6753F11]\n",
      "\t(No symbol) [0x00007FF6D67F1652]\n",
      "\t(No symbol) [0x00007FF6D67C7C2A]\n",
      "\t(No symbol) [0x00007FF6D67F02F3]\n",
      "\t(No symbol) [0x00007FF6D67C7A03]\n",
      "\t(No symbol) [0x00007FF6D67906D0]\n",
      "\t(No symbol) [0x00007FF6D6791983]\n",
      "\tGetHandleVerifier [0x00007FF6D6CB67CD+3579853]\n",
      "\tGetHandleVerifier [0x00007FF6D6CCD1D2+3672530]\n",
      "\tGetHandleVerifier [0x00007FF6D6CC2153+3627347]\n",
      "\tGetHandleVerifier [0x00007FF6D6A2092A+868650]\n",
      "\t(No symbol) [0x00007FF6D68C2FFF]\n",
      "\t(No symbol) [0x00007FF6D68BF4A4]\n",
      "\t(No symbol) [0x00007FF6D68BF646]\n",
      "\t(No symbol) [0x00007FF6D68AEAA9]\n",
      "\tBaseThreadInitThunk [0x00007FF93949E8D7+23]\n",
      "\tRtlUserThreadStart [0x00007FF93A3BBF6C+44]\n",
      "\n",
      "Failed to click 'Read all reviews' button: Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF6D6C54C25+3179557]\n",
      "\t(No symbol) [0x00007FF6D68B88A0]\n",
      "\t(No symbol) [0x00007FF6D67491CA]\n",
      "\t(No symbol) [0x00007FF6D679FA67]\n",
      "\t(No symbol) [0x00007FF6D679FC9C]\n",
      "\t(No symbol) [0x00007FF6D67F3627]\n",
      "\t(No symbol) [0x00007FF6D67C7C6F]\n",
      "\t(No symbol) [0x00007FF6D67F02F3]\n",
      "\t(No symbol) [0x00007FF6D67C7A03]\n",
      "\t(No symbol) [0x00007FF6D67906D0]\n",
      "\t(No symbol) [0x00007FF6D6791983]\n",
      "\tGetHandleVerifier [0x00007FF6D6CB67CD+3579853]\n",
      "\tGetHandleVerifier [0x00007FF6D6CCD1D2+3672530]\n",
      "\tGetHandleVerifier [0x00007FF6D6CC2153+3627347]\n",
      "\tGetHandleVerifier [0x00007FF6D6A2092A+868650]\n",
      "\t(No symbol) [0x00007FF6D68C2FFF]\n",
      "\t(No symbol) [0x00007FF6D68BF4A4]\n",
      "\t(No symbol) [0x00007FF6D68BF646]\n",
      "\t(No symbol) [0x00007FF6D68AEAA9]\n",
      "\tBaseThreadInitThunk [0x00007FF93949E8D7+23]\n",
      "\tRtlUserThreadStart [0x00007FF93A3BBF6C+44]\n",
      "\n",
      "🚨 Error while scraping reviews: Message: \n",
      "🚨 Error while scraping reviews: Message: \n",
      "\n",
      "\n",
      "🚨 Error while scraping reviews: Message: \n",
      "\n",
      "🚨 Error while scraping reviews: Message: \n",
      "\n",
      "🚨 Error while scraping reviews: Message: \n",
      "\n",
      "🚨 Error while scraping reviews: Message: \n",
      "\n",
      "🚨 Error while scraping reviews: Message: \n",
      "\n",
      "🚨 Error while scraping reviews: Message: \n",
      "\n",
      "🚨 Error while scraping reviews: Message: \n",
      "\n",
      "Failed to click 'Read all reviews' button: Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF6D6C54C25+3179557]\n",
      "\t(No symbol) [0x00007FF6D68B88A0]\n",
      "\t(No symbol) [0x00007FF6D67491CA]\n",
      "\t(No symbol) [0x00007FF6D679FA67]\n",
      "\t(No symbol) [0x00007FF6D679FC9C]\n",
      "\t(No symbol) [0x00007FF6D67F3627]\n",
      "\t(No symbol) [0x00007FF6D67C7C6F]\n",
      "\t(No symbol) [0x00007FF6D67F02F3]\n",
      "\t(No symbol) [0x00007FF6D67C7A03]\n",
      "\t(No symbol) [0x00007FF6D67906D0]\n",
      "\t(No symbol) [0x00007FF6D6791983]\n",
      "\tGetHandleVerifier [0x00007FF6D6CB67CD+3579853]\n",
      "\tGetHandleVerifier [0x00007FF6D6CCD1D2+3672530]\n",
      "\tGetHandleVerifier [0x00007FF6D6CC2153+3627347]\n",
      "\tGetHandleVerifier [0x00007FF6D6A2092A+868650]\n",
      "\t(No symbol) [0x00007FF6D68C2FFF]\n",
      "\t(No symbol) [0x00007FF6D68BF4A4]\n",
      "\t(No symbol) [0x00007FF6D68BF646]\n",
      "\t(No symbol) [0x00007FF6D68AEAA9]\n",
      "\tBaseThreadInitThunk [0x00007FF93949E8D7+23]\n",
      "\tRtlUserThreadStart [0x00007FF93A3BBF6C+44]\n",
      "\n",
      "🚨 Error while scraping reviews: Message: \n",
      "\n",
      "Failed to click 'Read all reviews' button: Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF6D6C54C25+3179557]\n",
      "\t(No symbol) [0x00007FF6D68B88A0]\n",
      "\t(No symbol) [0x00007FF6D67491CA]\n",
      "\t(No symbol) [0x00007FF6D679FA67]\n",
      "\t(No symbol) [0x00007FF6D679FC9C]\n",
      "\t(No symbol) [0x00007FF6D67F3627]\n",
      "\t(No symbol) [0x00007FF6D67C7C6F]\n",
      "\t(No symbol) [0x00007FF6D67F02F3]\n",
      "\t(No symbol) [0x00007FF6D67C7A03]\n",
      "\t(No symbol) [0x00007FF6D67906D0]\n",
      "\t(No symbol) [0x00007FF6D6791983]\n",
      "\tGetHandleVerifier [0x00007FF6D6CB67CD+3579853]\n",
      "\tGetHandleVerifier [0x00007FF6D6CCD1D2+3672530]\n",
      "\tGetHandleVerifier [0x00007FF6D6CC2153+3627347]\n",
      "\tGetHandleVerifier [0x00007FF6D6A2092A+868650]\n",
      "\t(No symbol) [0x00007FF6D68C2FFF]\n",
      "\t(No symbol) [0x00007FF6D68BF4A4]\n",
      "\t(No symbol) [0x00007FF6D68BF646]\n",
      "\t(No symbol) [0x00007FF6D68AEAA9]\n",
      "\tBaseThreadInitThunk [0x00007FF93949E8D7+23]\n",
      "\tRtlUserThreadStart [0x00007FF93A3BBF6C+44]\n",
      "\n",
      "🚨 Error while scraping reviews: Message: \n",
      "\n",
      "Failed to click 'Read all reviews' button: Message: stale element reference: stale element not found in the current frame\n",
      "  (Session info: chrome=134.0.6998.118); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#stale-element-reference-exception\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF6D6C54C25+3179557]\n",
      "\t(No symbol) [0x00007FF6D68B88A0]\n",
      "\t(No symbol) [0x00007FF6D67491CA]\n",
      "\t(No symbol) [0x00007FF6D6750B98]\n",
      "\t(No symbol) [0x00007FF6D6753F11]\n",
      "\t(No symbol) [0x00007FF6D67F1652]\n",
      "\t(No symbol) [0x00007FF6D67C7C2A]\n",
      "\t(No symbol) [0x00007FF6D67F02F3]\n",
      "\t(No symbol) [0x00007FF6D67C7A03]\n",
      "\t(No symbol) [0x00007FF6D67906D0]\n",
      "\t(No symbol) [0x00007FF6D6791983]\n",
      "\tGetHandleVerifier [0x00007FF6D6CB67CD+3579853]\n",
      "\tGetHandleVerifier [0x00007FF6D6CCD1D2+3672530]\n",
      "\tGetHandleVerifier [0x00007FF6D6CC2153+3627347]\n",
      "\tGetHandleVerifier [0x00007FF6D6A2092A+868650]\n",
      "\t(No symbol) [0x00007FF6D68C2FFF]\n",
      "\t(No symbol) [0x00007FF6D68BF4A4]\n",
      "\t(No symbol) [0x00007FF6D68BF646]\n",
      "\t(No symbol) [0x00007FF6D68AEAA9]\n",
      "\tBaseThreadInitThunk [0x00007FF93949E8D7+23]\n",
      "\tRtlUserThreadStart [0x00007FF93A3BBF6C+44]\n",
      "\n",
      "Failed to click 'Read all reviews' button: Message: stale element reference: stale element not found in the current frame\n",
      "  (Session info: chrome=134.0.6998.118); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#stale-element-reference-exception\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF6D6C54C25+3179557]\n",
      "\t(No symbol) [0x00007FF6D68B88A0]\n",
      "\t(No symbol) [0x00007FF6D67491CA]\n",
      "\t(No symbol) [0x00007FF6D6750B98]\n",
      "\t(No symbol) [0x00007FF6D6753F11]\n",
      "\t(No symbol) [0x00007FF6D67F1652]\n",
      "\t(No symbol) [0x00007FF6D67C7C2A]\n",
      "\t(No symbol) [0x00007FF6D67F02F3]\n",
      "\t(No symbol) [0x00007FF6D67C7A03]\n",
      "\t(No symbol) [0x00007FF6D67906D0]\n",
      "\t(No symbol) [0x00007FF6D6791983]\n",
      "\tGetHandleVerifier [0x00007FF6D6CB67CD+3579853]\n",
      "\tGetHandleVerifier [0x00007FF6D6CCD1D2+3672530]\n",
      "\tGetHandleVerifier [0x00007FF6D6CC2153+3627347]\n",
      "\tGetHandleVerifier [0x00007FF6D6A2092A+868650]\n",
      "\t(No symbol) [0x00007FF6D68C2FFF]\n",
      "\t(No symbol) [0x00007FF6D68BF4A4]\n",
      "\t(No symbol) [0x00007FF6D68BF646]\n",
      "\t(No symbol) [0x00007FF6D68AEAA9]\n",
      "\tBaseThreadInitThunk [0x00007FF93949E8D7+23]\n",
      "\tRtlUserThreadStart [0x00007FF93A3BBF6C+44]\n",
      "\n",
      "Failed to click 'Read all reviews' button: Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF6D6C54C25+3179557]\n",
      "\t(No symbol) [0x00007FF6D68B88A0]\n",
      "\t(No symbol) [0x00007FF6D67491CA]\n",
      "\t(No symbol) [0x00007FF6D679FA67]\n",
      "\t(No symbol) [0x00007FF6D679FC9C]\n",
      "\t(No symbol) [0x00007FF6D67F3627]\n",
      "\t(No symbol) [0x00007FF6D67C7C6F]\n",
      "\t(No symbol) [0x00007FF6D67F02F3]\n",
      "\t(No symbol) [0x00007FF6D67C7A03]\n",
      "\t(No symbol) [0x00007FF6D67906D0]\n",
      "\t(No symbol) [0x00007FF6D6791983]\n",
      "\tGetHandleVerifier [0x00007FF6D6CB67CD+3579853]\n",
      "\tGetHandleVerifier [0x00007FF6D6CCD1D2+3672530]\n",
      "\tGetHandleVerifier [0x00007FF6D6CC2153+3627347]\n",
      "\tGetHandleVerifier [0x00007FF6D6A2092A+868650]\n",
      "\t(No symbol) [0x00007FF6D68C2FFF]\n",
      "\t(No symbol) [0x00007FF6D68BF4A4]\n",
      "\t(No symbol) [0x00007FF6D68BF646]\n",
      "\t(No symbol) [0x00007FF6D68AEAA9]\n",
      "\tBaseThreadInitThunk [0x00007FF93949E8D7+23]\n",
      "\tRtlUserThreadStart [0x00007FF93A3BBF6C+44]\n",
      "\n",
      "Failed to click 'Read all reviews' button: Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF6D6C54C25+3179557]\n",
      "\t(No symbol) [0x00007FF6D68B88A0]\n",
      "\t(No symbol) [0x00007FF6D67491CA]\n",
      "\t(No symbol) [0x00007FF6D679FA67]\n",
      "\t(No symbol) [0x00007FF6D679FC9C]\n",
      "\t(No symbol) [0x00007FF6D67F3627]\n",
      "\t(No symbol) [0x00007FF6D67C7C6F]\n",
      "\t(No symbol) [0x00007FF6D67F02F3]\n",
      "\t(No symbol) [0x00007FF6D67C7A03]\n",
      "\t(No symbol) [0x00007FF6D67906D0]\n",
      "\t(No symbol) [0x00007FF6D6791983]\n",
      "\tGetHandleVerifier [0x00007FF6D6CB67CD+3579853]\n",
      "\tGetHandleVerifier [0x00007FF6D6CCD1D2+3672530]\n",
      "\tGetHandleVerifier [0x00007FF6D6CC2153+3627347]\n",
      "\tGetHandleVerifier [0x00007FF6D6A2092A+868650]\n",
      "\t(No symbol) [0x00007FF6D68C2FFF]\n",
      "\t(No symbol) [0x00007FF6D68BF4A4]\n",
      "\t(No symbol) [0x00007FF6D68BF646]\n",
      "\t(No symbol) [0x00007FF6D68AEAA9]\n",
      "\tBaseThreadInitThunk [0x00007FF93949E8D7+23]\n",
      "\tRtlUserThreadStart [0x00007FF93A3BBF6C+44]\n",
      "\n",
      "🚨 Error while scraping reviews: Message: \n",
      "\n",
      "Failed to click 'Read all reviews' button: Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF6D6C54C25+3179557]\n",
      "\t(No symbol) [0x00007FF6D68B88A0]\n",
      "\t(No symbol) [0x00007FF6D67491CA]\n",
      "\t(No symbol) [0x00007FF6D679FA67]\n",
      "\t(No symbol) [0x00007FF6D679FC9C]\n",
      "\t(No symbol) [0x00007FF6D67F3627]\n",
      "\t(No symbol) [0x00007FF6D67C7C6F]\n",
      "\t(No symbol) [0x00007FF6D67F02F3]\n",
      "\t(No symbol) [0x00007FF6D67C7A03]\n",
      "\t(No symbol) [0x00007FF6D67906D0]\n",
      "\t(No symbol) [0x00007FF6D6791983]\n",
      "\tGetHandleVerifier [0x00007FF6D6CB67CD+3579853]\n",
      "\tGetHandleVerifier [0x00007FF6D6CCD1D2+3672530]\n",
      "\tGetHandleVerifier [0x00007FF6D6CC2153+3627347]\n",
      "\tGetHandleVerifier [0x00007FF6D6A2092A+868650]\n",
      "\t(No symbol) [0x00007FF6D68C2FFF]\n",
      "\t(No symbol) [0x00007FF6D68BF4A4]\n",
      "\t(No symbol) [0x00007FF6D68BF646]\n",
      "\t(No symbol) [0x00007FF6D68AEAA9]\n",
      "\tBaseThreadInitThunk [0x00007FF93949E8D7+23]\n",
      "\tRtlUserThreadStart [0x00007FF93A3BBF6C+44]\n",
      "\n",
      "Failed to click 'Read all reviews' button: Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF6D6C54C25+3179557]\n",
      "\t(No symbol) [0x00007FF6D68B88A0]\n",
      "\t(No symbol) [0x00007FF6D67491CA]\n",
      "\t(No symbol) [0x00007FF6D679FA67]\n",
      "\t(No symbol) [0x00007FF6D679FC9C]\n",
      "\t(No symbol) [0x00007FF6D67F3627]\n",
      "\t(No symbol) [0x00007FF6D67C7C6F]\n",
      "\t(No symbol) [0x00007FF6D67F02F3]\n",
      "\t(No symbol) [0x00007FF6D67C7A03]\n",
      "\t(No symbol) [0x00007FF6D67906D0]\n",
      "\t(No symbol) [0x00007FF6D6791983]\n",
      "\tGetHandleVerifier [0x00007FF6D6CB67CD+3579853]\n",
      "\tGetHandleVerifier [0x00007FF6D6CCD1D2+3672530]\n",
      "\tGetHandleVerifier [0x00007FF6D6CC2153+3627347]\n",
      "\tGetHandleVerifier [0x00007FF6D6A2092A+868650]\n",
      "\t(No symbol) [0x00007FF6D68C2FFF]\n",
      "\t(No symbol) [0x00007FF6D68BF4A4]\n",
      "\t(No symbol) [0x00007FF6D68BF646]\n",
      "\t(No symbol) [0x00007FF6D68AEAA9]\n",
      "\tBaseThreadInitThunk [0x00007FF93949E8D7+23]\n",
      "\tRtlUserThreadStart [0x00007FF93A3BBF6C+44]\n",
      "\n",
      "Failed to click 'Read all reviews' button: Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF6D6C54C25+3179557]\n",
      "\t(No symbol) [0x00007FF6D68B88A0]\n",
      "\t(No symbol) [0x00007FF6D67491CA]\n",
      "\t(No symbol) [0x00007FF6D679FA67]\n",
      "\t(No symbol) [0x00007FF6D679FC9C]\n",
      "\t(No symbol) [0x00007FF6D67F3627]\n",
      "\t(No symbol) [0x00007FF6D67C7C6F]\n",
      "\t(No symbol) [0x00007FF6D67F02F3]\n",
      "\t(No symbol) [0x00007FF6D67C7A03]\n",
      "\t(No symbol) [0x00007FF6D67906D0]\n",
      "\t(No symbol) [0x00007FF6D6791983]\n",
      "\tGetHandleVerifier [0x00007FF6D6CB67CD+3579853]\n",
      "\tGetHandleVerifier [0x00007FF6D6CCD1D2+3672530]\n",
      "\tGetHandleVerifier [0x00007FF6D6CC2153+3627347]\n",
      "\tGetHandleVerifier [0x00007FF6D6A2092A+868650]\n",
      "\t(No symbol) [0x00007FF6D68C2FFF]\n",
      "\t(No symbol) [0x00007FF6D68BF4A4]\n",
      "\t(No symbol) [0x00007FF6D68BF646]\n",
      "\t(No symbol) [0x00007FF6D68AEAA9]\n",
      "\tBaseThreadInitThunk [0x00007FF93949E8D7+23]\n",
      "\tRtlUserThreadStart [0x00007FF93A3BBF6C+44]\n",
      "\n",
      "Failed to click 'Read all reviews' button: Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF6D6C54C25+3179557]\n",
      "\t(No symbol) [0x00007FF6D68B88A0]\n",
      "\t(No symbol) [0x00007FF6D67491CA]\n",
      "\t(No symbol) [0x00007FF6D679FA67]\n",
      "\t(No symbol) [0x00007FF6D679FC9C]\n",
      "\t(No symbol) [0x00007FF6D67F3627]\n",
      "\t(No symbol) [0x00007FF6D67C7C6F]\n",
      "\t(No symbol) [0x00007FF6D67F02F3]\n",
      "\t(No symbol) [0x00007FF6D67C7A03]\n",
      "\t(No symbol) [0x00007FF6D67906D0]\n",
      "\t(No symbol) [0x00007FF6D6791983]\n",
      "\tGetHandleVerifier [0x00007FF6D6CB67CD+3579853]\n",
      "\tGetHandleVerifier [0x00007FF6D6CCD1D2+3672530]\n",
      "\tGetHandleVerifier [0x00007FF6D6CC2153+3627347]\n",
      "\tGetHandleVerifier [0x00007FF6D6A2092A+868650]\n",
      "\t(No symbol) [0x00007FF6D68C2FFF]\n",
      "\t(No symbol) [0x00007FF6D68BF4A4]\n",
      "\t(No symbol) [0x00007FF6D68BF646]\n",
      "\t(No symbol) [0x00007FF6D68AEAA9]\n",
      "\tBaseThreadInitThunk [0x00007FF93949E8D7+23]\n",
      "\tRtlUserThreadStart [0x00007FF93A3BBF6C+44]\n",
      "\n",
      "Failed to click 'Read all reviews' button: Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF6D6C54C25+3179557]\n",
      "\t(No symbol) [0x00007FF6D68B88A0]\n",
      "\t(No symbol) [0x00007FF6D67491CA]\n",
      "\t(No symbol) [0x00007FF6D679FA67]\n",
      "\t(No symbol) [0x00007FF6D679FC9C]\n",
      "\t(No symbol) [0x00007FF6D67F3627]\n",
      "\t(No symbol) [0x00007FF6D67C7C6F]\n",
      "\t(No symbol) [0x00007FF6D67F02F3]\n",
      "\t(No symbol) [0x00007FF6D67C7A03]\n",
      "\t(No symbol) [0x00007FF6D67906D0]\n",
      "\t(No symbol) [0x00007FF6D6791983]\n",
      "\tGetHandleVerifier [0x00007FF6D6CB67CD+3579853]\n",
      "\tGetHandleVerifier [0x00007FF6D6CCD1D2+3672530]\n",
      "\tGetHandleVerifier [0x00007FF6D6CC2153+3627347]\n",
      "\tGetHandleVerifier [0x00007FF6D6A2092A+868650]\n",
      "\t(No symbol) [0x00007FF6D68C2FFF]\n",
      "\t(No symbol) [0x00007FF6D68BF4A4]\n",
      "\t(No symbol) [0x00007FF6D68BF646]\n",
      "\t(No symbol) [0x00007FF6D68AEAA9]\n",
      "\tBaseThreadInitThunk [0x00007FF93949E8D7+23]\n",
      "\tRtlUserThreadStart [0x00007FF93A3BBF6C+44]\n",
      "\n",
      "🚨 Error while scraping reviews: Message: \n",
      "\n",
      "🚨 Error while scraping reviews: Message: \n",
      "\n",
      "🚨 Error while scraping reviews: Message: \n",
      "\n",
      "Failed to click 'Read all reviews' button: Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF6D6C54C25+3179557]\n",
      "\t(No symbol) [0x00007FF6D68B88A0]\n",
      "\t(No symbol) [0x00007FF6D67491CA]\n",
      "\t(No symbol) [0x00007FF6D679FA67]\n",
      "\t(No symbol) [0x00007FF6D679FC9C]\n",
      "\t(No symbol) [0x00007FF6D67F3627]\n",
      "\t(No symbol) [0x00007FF6D67C7C6F]\n",
      "\t(No symbol) [0x00007FF6D67F02F3]\n",
      "\t(No symbol) [0x00007FF6D67C7A03]\n",
      "\t(No symbol) [0x00007FF6D67906D0]\n",
      "\t(No symbol) [0x00007FF6D6791983]\n",
      "\tGetHandleVerifier [0x00007FF6D6CB67CD+3579853]\n",
      "\tGetHandleVerifier [0x00007FF6D6CCD1D2+3672530]\n",
      "\tGetHandleVerifier [0x00007FF6D6CC2153+3627347]\n",
      "\tGetHandleVerifier [0x00007FF6D6A2092A+868650]\n",
      "\t(No symbol) [0x00007FF6D68C2FFF]\n",
      "\t(No symbol) [0x00007FF6D68BF4A4]\n",
      "\t(No symbol) [0x00007FF6D68BF646]\n",
      "\t(No symbol) [0x00007FF6D68AEAA9]\n",
      "\tBaseThreadInitThunk [0x00007FF93949E8D7+23]\n",
      "\tRtlUserThreadStart [0x00007FF93A3BBF6C+44]\n",
      "\n",
      "🚨 Error while scraping reviews: Message: \n",
      "\n",
      "Failed to click 'Read all reviews' button: Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF6D6C54C25+3179557]\n",
      "\t(No symbol) [0x00007FF6D68B88A0]\n",
      "\t(No symbol) [0x00007FF6D67491CA]\n",
      "\t(No symbol) [0x00007FF6D679FA67]\n",
      "\t(No symbol) [0x00007FF6D679FC9C]\n",
      "\t(No symbol) [0x00007FF6D67F3627]\n",
      "\t(No symbol) [0x00007FF6D67C7C6F]\n",
      "\t(No symbol) [0x00007FF6D67F02F3]\n",
      "\t(No symbol) [0x00007FF6D67C7A03]\n",
      "\t(No symbol) [0x00007FF6D67906D0]\n",
      "\t(No symbol) [0x00007FF6D6791983]\n",
      "\tGetHandleVerifier [0x00007FF6D6CB67CD+3579853]\n",
      "\tGetHandleVerifier [0x00007FF6D6CCD1D2+3672530]\n",
      "\tGetHandleVerifier [0x00007FF6D6CC2153+3627347]\n",
      "\tGetHandleVerifier [0x00007FF6D6A2092A+868650]\n",
      "\t(No symbol) [0x00007FF6D68C2FFF]\n",
      "\t(No symbol) [0x00007FF6D68BF4A4]\n",
      "\t(No symbol) [0x00007FF6D68BF646]\n",
      "\t(No symbol) [0x00007FF6D68AEAA9]\n",
      "\tBaseThreadInitThunk [0x00007FF93949E8D7+23]\n",
      "\tRtlUserThreadStart [0x00007FF93A3BBF6C+44]\n",
      "\n",
      "🚨 Error while scraping reviews: Message: \n",
      "\n",
      "🚨 Error while scraping reviews: Message: \n",
      "\n",
      "🚨 Error while scraping reviews: Message: \n",
      "\n",
      "🚨 Error while scraping reviews: Message: \n",
      "\n",
      "🚨 Error while scraping reviews: Message: \n",
      "\n",
      "Failed to click 'Read all reviews' button: Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF6D6C54C25+3179557]\n",
      "\t(No symbol) [0x00007FF6D68B88A0]\n",
      "\t(No symbol) [0x00007FF6D67491CA]\n",
      "\t(No symbol) [0x00007FF6D679FA67]\n",
      "\t(No symbol) [0x00007FF6D679FC9C]\n",
      "\t(No symbol) [0x00007FF6D67F3627]\n",
      "\t(No symbol) [0x00007FF6D67C7C6F]\n",
      "\t(No symbol) [0x00007FF6D67F02F3]\n",
      "\t(No symbol) [0x00007FF6D67C7A03]\n",
      "\t(No symbol) [0x00007FF6D67906D0]\n",
      "\t(No symbol) [0x00007FF6D6791983]\n",
      "\tGetHandleVerifier [0x00007FF6D6CB67CD+3579853]\n",
      "\tGetHandleVerifier [0x00007FF6D6CCD1D2+3672530]\n",
      "\tGetHandleVerifier [0x00007FF6D6CC2153+3627347]\n",
      "\tGetHandleVerifier [0x00007FF6D6A2092A+868650]\n",
      "\t(No symbol) [0x00007FF6D68C2FFF]\n",
      "\t(No symbol) [0x00007FF6D68BF4A4]\n",
      "\t(No symbol) [0x00007FF6D68BF646]\n",
      "\t(No symbol) [0x00007FF6D68AEAA9]\n",
      "\tBaseThreadInitThunk [0x00007FF93949E8D7+23]\n",
      "\tRtlUserThreadStart [0x00007FF93A3BBF6C+44]\n",
      "\n",
      "🚨 Error while scraping reviews: Message: \n",
      "\n",
      "🚨 Error while scraping reviews: Message: \n",
      "\n",
      "Failed to click 'Read all reviews' button: Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF6D6C54C25+3179557]\n",
      "\t(No symbol) [0x00007FF6D68B88A0]\n",
      "\t(No symbol) [0x00007FF6D67491CA]\n",
      "\t(No symbol) [0x00007FF6D679FA67]\n",
      "\t(No symbol) [0x00007FF6D679FC9C]\n",
      "\t(No symbol) [0x00007FF6D67F3627]\n",
      "\t(No symbol) [0x00007FF6D67C7C6F]\n",
      "\t(No symbol) [0x00007FF6D67F02F3]\n",
      "\t(No symbol) [0x00007FF6D67C7A03]\n",
      "\t(No symbol) [0x00007FF6D67906D0]\n",
      "\t(No symbol) [0x00007FF6D6791983]\n",
      "\tGetHandleVerifier [0x00007FF6D6CB67CD+3579853]\n",
      "\tGetHandleVerifier [0x00007FF6D6CCD1D2+3672530]\n",
      "\tGetHandleVerifier [0x00007FF6D6CC2153+3627347]\n",
      "\tGetHandleVerifier [0x00007FF6D6A2092A+868650]\n",
      "\t(No symbol) [0x00007FF6D68C2FFF]\n",
      "\t(No symbol) [0x00007FF6D68BF4A4]\n",
      "\t(No symbol) [0x00007FF6D68BF646]\n",
      "\t(No symbol) [0x00007FF6D68AEAA9]\n",
      "\tBaseThreadInitThunk [0x00007FF93949E8D7+23]\n",
      "\tRtlUserThreadStart [0x00007FF93A3BBF6C+44]\n",
      "\n",
      "Failed to click 'Read all reviews' button: Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF6D6C54C25+3179557]\n",
      "\t(No symbol) [0x00007FF6D68B88A0]\n",
      "\t(No symbol) [0x00007FF6D67491CA]\n",
      "\t(No symbol) [0x00007FF6D679FA67]\n",
      "\t(No symbol) [0x00007FF6D679FC9C]\n",
      "\t(No symbol) [0x00007FF6D67F3627]\n",
      "\t(No symbol) [0x00007FF6D67C7C6F]\n",
      "\t(No symbol) [0x00007FF6D67F02F3]\n",
      "\t(No symbol) [0x00007FF6D67C7A03]\n",
      "\t(No symbol) [0x00007FF6D67906D0]\n",
      "\t(No symbol) [0x00007FF6D6791983]\n",
      "\tGetHandleVerifier [0x00007FF6D6CB67CD+3579853]\n",
      "\tGetHandleVerifier [0x00007FF6D6CCD1D2+3672530]\n",
      "\tGetHandleVerifier [0x00007FF6D6CC2153+3627347]\n",
      "\tGetHandleVerifier [0x00007FF6D6A2092A+868650]\n",
      "\t(No symbol) [0x00007FF6D68C2FFF]\n",
      "\t(No symbol) [0x00007FF6D68BF4A4]\n",
      "\t(No symbol) [0x00007FF6D68BF646]\n",
      "\t(No symbol) [0x00007FF6D68AEAA9]\n",
      "\tBaseThreadInitThunk [0x00007FF93949E8D7+23]\n",
      "\tRtlUserThreadStart [0x00007FF93A3BBF6C+44]\n",
      "\n",
      "🚨 Error while scraping reviews: Message: \n",
      "\n",
      "Failed to click 'Read all reviews' button: Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF6D6C54C25+3179557]\n",
      "\t(No symbol) [0x00007FF6D68B88A0]\n",
      "\t(No symbol) [0x00007FF6D67491CA]\n",
      "\t(No symbol) [0x00007FF6D679FA67]\n",
      "\t(No symbol) [0x00007FF6D679FC9C]\n",
      "\t(No symbol) [0x00007FF6D67F3627]\n",
      "\t(No symbol) [0x00007FF6D67C7C6F]\n",
      "\t(No symbol) [0x00007FF6D67F02F3]\n",
      "\t(No symbol) [0x00007FF6D67C7A03]\n",
      "\t(No symbol) [0x00007FF6D67906D0]\n",
      "\t(No symbol) [0x00007FF6D6791983]\n",
      "\tGetHandleVerifier [0x00007FF6D6CB67CD+3579853]\n",
      "\tGetHandleVerifier [0x00007FF6D6CCD1D2+3672530]\n",
      "\tGetHandleVerifier [0x00007FF6D6CC2153+3627347]\n",
      "\tGetHandleVerifier [0x00007FF6D6A2092A+868650]\n",
      "\t(No symbol) [0x00007FF6D68C2FFF]\n",
      "\t(No symbol) [0x00007FF6D68BF4A4]\n",
      "\t(No symbol) [0x00007FF6D68BF646]\n",
      "\t(No symbol) [0x00007FF6D68AEAA9]\n",
      "\tBaseThreadInitThunk [0x00007FF93949E8D7+23]\n",
      "\tRtlUserThreadStart [0x00007FF93A3BBF6C+44]\n",
      "\n",
      "Failed to click 'Read all reviews' button: Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF6D6C54C25+3179557]\n",
      "\t(No symbol) [0x00007FF6D68B88A0]\n",
      "\t(No symbol) [0x00007FF6D67491CA]\n",
      "\t(No symbol) [0x00007FF6D679FA67]\n",
      "\t(No symbol) [0x00007FF6D679FC9C]\n",
      "\t(No symbol) [0x00007FF6D67F3627]\n",
      "\t(No symbol) [0x00007FF6D67C7C6F]\n",
      "\t(No symbol) [0x00007FF6D67F02F3]\n",
      "\t(No symbol) [0x00007FF6D67C7A03]\n",
      "\t(No symbol) [0x00007FF6D67906D0]\n",
      "\t(No symbol) [0x00007FF6D6791983]\n",
      "\tGetHandleVerifier [0x00007FF6D6CB67CD+3579853]\n",
      "\tGetHandleVerifier [0x00007FF6D6CCD1D2+3672530]\n",
      "\tGetHandleVerifier [0x00007FF6D6CC2153+3627347]\n",
      "\tGetHandleVerifier [0x00007FF6D6A2092A+868650]\n",
      "\t(No symbol) [0x00007FF6D68C2FFF]\n",
      "\t(No symbol) [0x00007FF6D68BF4A4]\n",
      "\t(No symbol) [0x00007FF6D68BF646]\n",
      "\t(No symbol) [0x00007FF6D68AEAA9]\n",
      "\tBaseThreadInitThunk [0x00007FF93949E8D7+23]\n",
      "\tRtlUserThreadStart [0x00007FF93A3BBF6C+44]\n",
      "\n",
      "Failed to click 'Read all reviews' button: Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF6D6C54C25+3179557]\n",
      "\t(No symbol) [0x00007FF6D68B88A0]\n",
      "\t(No symbol) [0x00007FF6D67491CA]\n",
      "\t(No symbol) [0x00007FF6D679FA67]\n",
      "\t(No symbol) [0x00007FF6D679FC9C]\n",
      "\t(No symbol) [0x00007FF6D67F3627]\n",
      "\t(No symbol) [0x00007FF6D67C7C6F]\n",
      "\t(No symbol) [0x00007FF6D67F02F3]\n",
      "\t(No symbol) [0x00007FF6D67C7A03]\n",
      "\t(No symbol) [0x00007FF6D67906D0]\n",
      "\t(No symbol) [0x00007FF6D6791983]\n",
      "\tGetHandleVerifier [0x00007FF6D6CB67CD+3579853]\n",
      "\tGetHandleVerifier [0x00007FF6D6CCD1D2+3672530]\n",
      "\tGetHandleVerifier [0x00007FF6D6CC2153+3627347]\n",
      "\tGetHandleVerifier [0x00007FF6D6A2092A+868650]\n",
      "\t(No symbol) [0x00007FF6D68C2FFF]\n",
      "\t(No symbol) [0x00007FF6D68BF4A4]\n",
      "\t(No symbol) [0x00007FF6D68BF646]\n",
      "\t(No symbol) [0x00007FF6D68AEAA9]\n",
      "\tBaseThreadInitThunk [0x00007FF93949E8D7+23]\n",
      "\tRtlUserThreadStart [0x00007FF93A3BBF6C+44]\n",
      "\n",
      "Failed to click 'Read all reviews' button: Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF6D6C54C25+3179557]\n",
      "\t(No symbol) [0x00007FF6D68B88A0]\n",
      "\t(No symbol) [0x00007FF6D67491CA]\n",
      "\t(No symbol) [0x00007FF6D679FA67]\n",
      "\t(No symbol) [0x00007FF6D679FC9C]\n",
      "\t(No symbol) [0x00007FF6D67F3627]\n",
      "\t(No symbol) [0x00007FF6D67C7C6F]\n",
      "\t(No symbol) [0x00007FF6D67F02F3]\n",
      "\t(No symbol) [0x00007FF6D67C7A03]\n",
      "\t(No symbol) [0x00007FF6D67906D0]\n",
      "\t(No symbol) [0x00007FF6D6791983]\n",
      "\tGetHandleVerifier [0x00007FF6D6CB67CD+3579853]\n",
      "\tGetHandleVerifier [0x00007FF6D6CCD1D2+3672530]\n",
      "\tGetHandleVerifier [0x00007FF6D6CC2153+3627347]\n",
      "\tGetHandleVerifier [0x00007FF6D6A2092A+868650]\n",
      "\t(No symbol) [0x00007FF6D68C2FFF]\n",
      "\t(No symbol) [0x00007FF6D68BF4A4]\n",
      "\t(No symbol) [0x00007FF6D68BF646]\n",
      "\t(No symbol) [0x00007FF6D68AEAA9]\n",
      "\tBaseThreadInitThunk [0x00007FF93949E8D7+23]\n",
      "\tRtlUserThreadStart [0x00007FF93A3BBF6C+44]\n",
      "\n",
      "🚨 Error while scraping reviews: Message: \n",
      "\n",
      "🚨 Error while scraping reviews: Message: \n",
      "\n",
      "Failed to click 'Read all reviews' button: Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF6D6C54C25+3179557]\n",
      "\t(No symbol) [0x00007FF6D68B88A0]\n",
      "\t(No symbol) [0x00007FF6D67491CA]\n",
      "\t(No symbol) [0x00007FF6D679FA67]\n",
      "\t(No symbol) [0x00007FF6D679FC9C]\n",
      "\t(No symbol) [0x00007FF6D67F3627]\n",
      "\t(No symbol) [0x00007FF6D67C7C6F]\n",
      "\t(No symbol) [0x00007FF6D67F02F3]\n",
      "\t(No symbol) [0x00007FF6D67C7A03]\n",
      "\t(No symbol) [0x00007FF6D67906D0]\n",
      "\t(No symbol) [0x00007FF6D6791983]\n",
      "\tGetHandleVerifier [0x00007FF6D6CB67CD+3579853]\n",
      "\tGetHandleVerifier [0x00007FF6D6CCD1D2+3672530]\n",
      "\tGetHandleVerifier [0x00007FF6D6CC2153+3627347]\n",
      "\tGetHandleVerifier [0x00007FF6D6A2092A+868650]\n",
      "\t(No symbol) [0x00007FF6D68C2FFF]\n",
      "\t(No symbol) [0x00007FF6D68BF4A4]\n",
      "\t(No symbol) [0x00007FF6D68BF646]\n",
      "\t(No symbol) [0x00007FF6D68AEAA9]\n",
      "\tBaseThreadInitThunk [0x00007FF93949E8D7+23]\n",
      "\tRtlUserThreadStart [0x00007FF93A3BBF6C+44]\n",
      "\n",
      "Failed to click 'Read all reviews' button: Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF6D6C54C25+3179557]\n",
      "\t(No symbol) [0x00007FF6D68B88A0]\n",
      "\t(No symbol) [0x00007FF6D67491CA]\n",
      "\t(No symbol) [0x00007FF6D679FA67]\n",
      "\t(No symbol) [0x00007FF6D679FC9C]\n",
      "\t(No symbol) [0x00007FF6D67F3627]\n",
      "\t(No symbol) [0x00007FF6D67C7C6F]\n",
      "\t(No symbol) [0x00007FF6D67F02F3]\n",
      "\t(No symbol) [0x00007FF6D67C7A03]\n",
      "\t(No symbol) [0x00007FF6D67906D0]\n",
      "\t(No symbol) [0x00007FF6D6791983]\n",
      "\tGetHandleVerifier [0x00007FF6D6CB67CD+3579853]\n",
      "\tGetHandleVerifier [0x00007FF6D6CCD1D2+3672530]\n",
      "\tGetHandleVerifier [0x00007FF6D6CC2153+3627347]\n",
      "\tGetHandleVerifier [0x00007FF6D6A2092A+868650]\n",
      "\t(No symbol) [0x00007FF6D68C2FFF]\n",
      "\t(No symbol) [0x00007FF6D68BF4A4]\n",
      "\t(No symbol) [0x00007FF6D68BF646]\n",
      "\t(No symbol) [0x00007FF6D68AEAA9]\n",
      "\tBaseThreadInitThunk [0x00007FF93949E8D7+23]\n",
      "\tRtlUserThreadStart [0x00007FF93A3BBF6C+44]\n",
      "\n",
      "Failed to click 'Read all reviews' button: Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF6D6C54C25+3179557]\n",
      "\t(No symbol) [0x00007FF6D68B88A0]\n",
      "\t(No symbol) [0x00007FF6D67491CA]\n",
      "\t(No symbol) [0x00007FF6D679FA67]\n",
      "\t(No symbol) [0x00007FF6D679FC9C]\n",
      "\t(No symbol) [0x00007FF6D67F3627]\n",
      "\t(No symbol) [0x00007FF6D67C7C6F]\n",
      "\t(No symbol) [0x00007FF6D67F02F3]\n",
      "\t(No symbol) [0x00007FF6D67C7A03]\n",
      "\t(No symbol) [0x00007FF6D67906D0]\n",
      "\t(No symbol) [0x00007FF6D6791983]\n",
      "\tGetHandleVerifier [0x00007FF6D6CB67CD+3579853]\n",
      "\tGetHandleVerifier [0x00007FF6D6CCD1D2+3672530]\n",
      "\tGetHandleVerifier [0x00007FF6D6CC2153+3627347]\n",
      "\tGetHandleVerifier [0x00007FF6D6A2092A+868650]\n",
      "\t(No symbol) [0x00007FF6D68C2FFF]\n",
      "\t(No symbol) [0x00007FF6D68BF4A4]\n",
      "\t(No symbol) [0x00007FF6D68BF646]\n",
      "\t(No symbol) [0x00007FF6D68AEAA9]\n",
      "\tBaseThreadInitThunk [0x00007FF93949E8D7+23]\n",
      "\tRtlUserThreadStart [0x00007FF93A3BBF6C+44]\n",
      "\n",
      "🚨 Error while scraping reviews: Message: \n",
      "\n",
      "🚨 Error while scraping reviews: Message: \n",
      "\n",
      "🚨 Error while scraping reviews: Message: \n",
      "\n",
      "❌ Maximum retries reached. No reviews extracted.\n",
      "[Batch 376] Scraped 0 reviews for Downtown Apartment\n",
      "Failed to click 'Read all reviews' button: Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF6D6C54C25+3179557]\n",
      "\t(No symbol) [0x00007FF6D68B88A0]\n",
      "\t(No symbol) [0x00007FF6D67491CA]\n",
      "\t(No symbol) [0x00007FF6D679FA67]\n",
      "\t(No symbol) [0x00007FF6D679FC9C]\n",
      "\t(No symbol) [0x00007FF6D67F3627]\n",
      "\t(No symbol) [0x00007FF6D67C7C6F]\n",
      "\t(No symbol) [0x00007FF6D67F02F3]\n",
      "\t(No symbol) [0x00007FF6D67C7A03]\n",
      "\t(No symbol) [0x00007FF6D67906D0]\n",
      "\t(No symbol) [0x00007FF6D6791983]\n",
      "\tGetHandleVerifier [0x00007FF6D6CB67CD+3579853]\n",
      "\tGetHandleVerifier [0x00007FF6D6CCD1D2+3672530]\n",
      "\tGetHandleVerifier [0x00007FF6D6CC2153+3627347]\n",
      "\tGetHandleVerifier [0x00007FF6D6A2092A+868650]\n",
      "\t(No symbol) [0x00007FF6D68C2FFF]\n",
      "\t(No symbol) [0x00007FF6D68BF4A4]\n",
      "\t(No symbol) [0x00007FF6D68BF646]\n",
      "\t(No symbol) [0x00007FF6D68AEAA9]\n",
      "\tBaseThreadInitThunk [0x00007FF93949E8D7+23]\n",
      "\tRtlUserThreadStart [0x00007FF93A3BBF6C+44]\n",
      "\n",
      "🚨 Error while scraping reviews: Message: \n",
      "\n",
      "❌ Maximum retries reached. No reviews extracted.\n",
      "[Batch 374] Scraped 0 reviews for A Desker Hotel, Stay From 6PM to 9AM\n",
      "🚨 Error while scraping reviews: Message: \n",
      "\n",
      "🚨 Error while scraping reviews: Message: \n",
      "\n",
      "🚨 Error while scraping reviews: Message: \n",
      "\n",
      "❌ Maximum retries reached. No reviews extracted.\n",
      "[Batch 432] Scraped 0 reviews for The Quay Hotel Little India\n",
      "❌ Maximum retries reached. No reviews extracted.\n",
      "[Batch 381] Scraped 0 reviews for Ultra Luxury Family House\n",
      "❌ Maximum retries reached. No reviews extracted.\n",
      "[Batch 363] Scraped 0 reviews for Social-Inn Norris Road Apt\n",
      "❌ Maximum retries reached. No reviews extracted.\n",
      "[Batch 382] Scraped 0 reviews for Raffles Sentosa Singapore\n",
      "🚨 Error while scraping reviews: Message: \n",
      "\n",
      "❌ Maximum retries reached. No reviews extracted.\n",
      "[Batch 383] Scraped 0 reviews for Bart house\n",
      "❌ Maximum retries reached. No reviews extracted.\n",
      "[Batch 387] Scraped 0 reviews for MASTER BEDROOM SUITE\n",
      "❌ Maximum retries reached. No reviews extracted.\n",
      "[Batch 415] Scraped 0 reviews for Mandai Rainforest Resort by Banyan Tree\n",
      "❌ Maximum retries reached. No reviews extracted.\n",
      "[Batch 378] Scraped 0 reviews for 36 club st residence\n",
      "⚠️ Stopping: 5 consecutive reviews without comments.\n",
      "[Batch 448] Scraped 9537 reviews for Marina Bay Sands\n",
      "[Batch 448] Saved to 'scraped_reviews\\booking_reviews_batch_448.csv'.\n",
      "⚠️ Stopping: 5 consecutive reviews without comments.\n",
      "[Batch 446] Scraped 9537 reviews for Marina Bay Sands\n",
      "[Batch 446] Saved to 'scraped_reviews\\booking_reviews_batch_446.csv'.\n",
      "⚠️ Stopping: 5 consecutive reviews without comments.\n",
      "[Batch 449] Scraped 9537 reviews for Marina Bay Sands\n",
      "⚠️ Stopping: 5 consecutive reviews without comments.\n",
      "[Batch 447] Scraped 9537 reviews for Marina Bay Sands\n",
      "[Batch 449] Saved to 'scraped_reviews\\booking_reviews_batch_449.csv'.\n",
      "[Batch 447] Saved to 'scraped_reviews\\booking_reviews_batch_447.csv'.\n",
      "⚠️ Stopping: 5 consecutive reviews without comments.\n",
      "[Batch 445] Scraped 9537 reviews for Marina Bay Sands\n",
      "[Batch 445] Saved to 'scraped_reviews\\booking_reviews_batch_445.csv'.\n",
      "\n",
      "✅ Scraping submitted for all remaining batches.\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# Scrape Reviews (SELENIUM GRID + PARALLEL) - MAIN SCRIPT\n",
    "# --------------------------\n",
    "import os\n",
    "import time\n",
    "import csv\n",
    "import random\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "\n",
    "# ---------- Setup ----------\n",
    "csv_filename = \"property_data.csv\"\n",
    "df = pd.read_csv(csv_filename)\n",
    "property_data = df.to_dict(orient=\"records\")\n",
    "\n",
    "batch_size = 1\n",
    "num_batches = len(property_data) // batch_size + (1 if len(property_data) % batch_size > 0 else 0)\n",
    "\n",
    "log_file = \"completed_batches.log\"\n",
    "output_folder = \"scraped_reviews\"\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "completed_batches = set()\n",
    "if os.path.exists(log_file):\n",
    "    with open(log_file, \"r\") as f:\n",
    "        completed_batches = {int(line.strip()) for line in f.readlines()}\n",
    "\n",
    "SELENIUM_GRID_URL = \"http://localhost:4445\"\n",
    "\n",
    "USER_AGENTS = [\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\"\n",
    "]\n",
    "\n",
    "# ---------- Parallel Scraping Function ----------\n",
    "def scrape_batch(i, batch, batch_output):\n",
    "    try:\n",
    "        print(f\"[Batch {i+1}] Starting scrape...\")\n",
    "\n",
    "        options = Options()\n",
    "        options.add_argument(\"--incognito\")\n",
    "        options.add_argument(f\"user-agent={random.choice(USER_AGENTS)}\")\n",
    "\n",
    "        driver = webdriver.Remote(\n",
    "            command_executor=SELENIUM_GRID_URL,\n",
    "            options=options\n",
    "        )\n",
    "        time.sleep(2)\n",
    "\n",
    "        all_hotel_reviews = []\n",
    "\n",
    "        for hotel in batch:\n",
    "            hotel_name = hotel[\"hotel_name\"]\n",
    "            hotel_url = hotel[\"hotel_url\"]\n",
    "\n",
    "            print(f\"[Batch {i+1}] Scraping: {hotel_name}\")\n",
    "            \n",
    "            driver.get(hotel_url)\n",
    "\n",
    "            time.sleep(3)\n",
    "\n",
    "            reviews = scrape_booking_reviews(driver)\n",
    "\n",
    "            for review in reviews:\n",
    "                review[\"hotel_name\"] = hotel_name\n",
    "                all_hotel_reviews.append(review)\n",
    "\n",
    "            print(f\"[Batch {i+1}] Scraped {len(reviews)} reviews for {hotel_name}\")\n",
    "\n",
    "        driver.quit()\n",
    "\n",
    "        if all_hotel_reviews:\n",
    "            with open(batch_output, \"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "                fieldnames = list(all_hotel_reviews[0].keys())\n",
    "                writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "                writer.writeheader()\n",
    "                writer.writerows(all_hotel_reviews)\n",
    "\n",
    "            print(f\"[Batch {i+1}] Saved to '{batch_output}'.\")\n",
    "\n",
    "            with open(log_file, \"a\") as f:\n",
    "                f.write(f\"{i}\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"[Batch {i+1}] 🚨 Error: {e}\")\n",
    "\n",
    "# ---------- Run Parallel Batches ----------\n",
    "tasks = []\n",
    "with ThreadPoolExecutor(max_workers=15) as executor:  # Adjust based on your Grid capacity\n",
    "    for i in range(num_batches):\n",
    "        if i in completed_batches:\n",
    "            print(f\"[Batch {i+1}] Skipped (already completed).\")\n",
    "            continue\n",
    "\n",
    "        batch = property_data[i * batch_size : (i + 1) * batch_size]\n",
    "        batch_output = os.path.join(output_folder, f\"booking_reviews_batch_{i+1}.csv\")\n",
    "        tasks.append(executor.submit(scrape_batch, i, batch, batch_output))\n",
    "\n",
    "print(\"\\n✅ Scraping submitted for all remaining batches.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hotel_id                                                              NaN\n",
       "reviewer_name                                                      Sergey\n",
       "reviewer_country                                                   Russia\n",
       "review_room_name                          Deluxe Plus Double or Twin Room\n",
       "review_num_nights                                                     3.0\n",
       "review_stay_date                                             October 2023\n",
       "review_traveler_type                                               Family\n",
       "review_score                                                          NaN\n",
       "review_title                                  Не соответствует ожиданиям.\n",
       "review_positive_text             Близко к метро, удобный спокойный район.\n",
       "review_negative_text    Старый отель, не соответствует описанию и цене...\n",
       "hotel_name              Rendezvous Hotel Singapore by Far East Hospita...\n",
       "Name: 11760, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"booking_reviews_batch_1_old.csv\", encoding=\"utf-8\")\n",
    "df.iloc[11760]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Merging Property Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged data saved to 'property_df.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "property_listing_df = pd.read_csv(\"property_data.csv\")\n",
    "property_details_df = pd.read_csv(\"booking_property_details.csv\")\n",
    "\n",
    "# Merge property listing & details data\n",
    "property_df = property_listing_df.merge(property_details_df, on=\"hotel_name\", how=\"left\")\n",
    "\n",
    "csv_filename = \"property_df.csv\"\n",
    "property_df.to_csv(csv_filename, index=False)\n",
    "print(f\"Merged data saved to '{csv_filename}'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Merging Reviews Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged book saved to 'property_data.csv'.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewer_name</th>\n",
       "      <th>reviewer_country</th>\n",
       "      <th>review_room_name</th>\n",
       "      <th>review_num_nights</th>\n",
       "      <th>review_stay_date</th>\n",
       "      <th>review_traveler_type</th>\n",
       "      <th>review_score</th>\n",
       "      <th>review_title</th>\n",
       "      <th>review_positive_text</th>\n",
       "      <th>review_negative_text</th>\n",
       "      <th>hotel_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gabriela</td>\n",
       "      <td>United States</td>\n",
       "      <td>Deluxe Twin, Window</td>\n",
       "      <td>2.0</td>\n",
       "      <td>January 2025</td>\n",
       "      <td>Family</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Comfortable and convenient</td>\n",
       "      <td>This was a last minute booking so we arrived t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A Hotel Joo Chiat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>James</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Superior Double, No Window</td>\n",
       "      <td>1.0</td>\n",
       "      <td>February 2025</td>\n",
       "      <td>Couple</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Very good</td>\n",
       "      <td>no breakfast</td>\n",
       "      <td>water in foyer</td>\n",
       "      <td>A Hotel Joo Chiat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Superior Double, No Window</td>\n",
       "      <td>4.0</td>\n",
       "      <td>February 2025</td>\n",
       "      <td>Couple</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Overall I'm quite happy with the stay except f...</td>\n",
       "      <td>The location is good.</td>\n",
       "      <td>A little costly for a budget hotel.</td>\n",
       "      <td>A Hotel Joo Chiat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sumarni</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Superior Twin, No Window</td>\n",
       "      <td>3.0</td>\n",
       "      <td>February 2025</td>\n",
       "      <td>Group</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Good and achieve my expectation</td>\n",
       "      <td>Easy access to anywhere</td>\n",
       "      <td>The fire alarm and no communication with the p...</td>\n",
       "      <td>A Hotel Joo Chiat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Samsul</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Deluxe Double, Window</td>\n",
       "      <td>6.0</td>\n",
       "      <td>February 2025</td>\n",
       "      <td>Couple</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Need room makeup… every stay..</td>\n",
       "      <td>we are regularly…the hotel need to overhaul…\\n...</td>\n",
       "      <td>Paid extra for little bit big &amp; View..\\nwith W...</td>\n",
       "      <td>A Hotel Joo Chiat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  reviewer_name reviewer_country            review_room_name  \\\n",
       "0      Gabriela    United States         Deluxe Twin, Window   \n",
       "1         James        Australia  Superior Double, No Window   \n",
       "2             A        Singapore  Superior Double, No Window   \n",
       "3       Sumarni        Australia    Superior Twin, No Window   \n",
       "4        Samsul        Australia       Deluxe Double, Window   \n",
       "\n",
       "   review_num_nights review_stay_date review_traveler_type  review_score  \\\n",
       "0                2.0     January 2025               Family          10.0   \n",
       "1                1.0    February 2025               Couple           8.0   \n",
       "2                4.0    February 2025               Couple           7.0   \n",
       "3                3.0    February 2025                Group           8.0   \n",
       "4                6.0    February 2025               Couple           8.0   \n",
       "\n",
       "                                        review_title  \\\n",
       "0                         Comfortable and convenient   \n",
       "1                                          Very good   \n",
       "2  Overall I'm quite happy with the stay except f...   \n",
       "3                    Good and achieve my expectation   \n",
       "4                     Need room makeup… every stay..   \n",
       "\n",
       "                                review_positive_text  \\\n",
       "0  This was a last minute booking so we arrived t...   \n",
       "1                                       no breakfast   \n",
       "2                              The location is good.   \n",
       "3                            Easy access to anywhere   \n",
       "4  we are regularly…the hotel need to overhaul…\\n...   \n",
       "\n",
       "                                review_negative_text         hotel_name  \n",
       "0                                                NaN  A Hotel Joo Chiat  \n",
       "1                                     water in foyer  A Hotel Joo Chiat  \n",
       "2                A little costly for a budget hotel.  A Hotel Joo Chiat  \n",
       "3  The fire alarm and no communication with the p...  A Hotel Joo Chiat  \n",
       "4  Paid extra for little bit big & View..\\nwith W...  A Hotel Joo Chiat  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# Path to your folder\n",
    "folder_path = \"scraped_reviews\"\n",
    "\n",
    "# Find all matching CSV files\n",
    "csv_files = glob(os.path.join(folder_path, \"booking_reviews_batch_*.csv\"))\n",
    "\n",
    "# Read and concatenate all CSV files into one DataFrame\n",
    "combined_df = pd.concat((pd.read_csv(file) for file in csv_files), ignore_index=True)\n",
    "\n",
    "# Save combined DataFrame to a new CSV file\n",
    "combined_df.to_csv(\"booking_reviews_combined.csv\", index=False)\n",
    "print(f\"Merged book saved to '{csv_filename}'.\")\n",
    "combined_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
